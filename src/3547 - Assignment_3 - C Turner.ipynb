{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc543f6-d439-4a9e-8f02-48620e6c8c68",
   "metadata": {},
   "source": [
    "### Assignment 3\n",
    "\n",
    "**Course**: 3547 - Intelligent Agents\n",
    "\n",
    "**Name**: Cameron Turner\n",
    "\n",
    "**Date**: December 9, 2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f386d78a-1150-44fb-bd32-f788b4c12ad1",
   "metadata": {},
   "source": [
    "Define the Global class which contains the application's global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0d8272-d961-41b3-807d-eefaa809c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global.py\n",
    "\n",
    "# Global variables.\n",
    "\n",
    "class Global:\n",
    "    \n",
    "    # Global variables.\n",
    "    \n",
    "    _display = False\n",
    "    _debug   = False\n",
    "    \n",
    "    # Start room.\n",
    "    \n",
    "    _start_room = (1, 1)\n",
    "    \n",
    "    # Probabilities.\n",
    "    \n",
    "    _pit_probability = 0.2\n",
    "    \n",
    "    # Directions\n",
    "    \n",
    "    _east  = \"east\"\n",
    "    _west  = \"west\"\n",
    "    _north = \"north\"\n",
    "    _south = \"south\"\n",
    "    \n",
    "    _left  = \"left\"\n",
    "    _right = \"right\"\n",
    "    \n",
    "    _orientation_array = [ _north, _east, _south, _west]\n",
    "    _facing_array      = [ _left, _right]\n",
    "    \n",
    "    # Actions\n",
    "    \n",
    "    _forward_action   = \"Forward\"\n",
    "    _turnLeft_action  = \"TurnLeft\"\n",
    "    _turnRight_action = \"TurnRight\"\n",
    "    _shoot_action     = \"Shoot\"\n",
    "    _grab_action      = \"Grab\"\n",
    "    _climb_action     = \"Climb\"\n",
    "    \n",
    "    # Define the set of actions an Agent can take.\n",
    "    \n",
    "    _action_array = [ _forward_action, _turnLeft_action, _turnRight_action, _shoot_action, _grab_action, _climb_action ]\n",
    "    \n",
    "    # Agent Fear Index\n",
    "    \n",
    "    _agent_fear_index = .5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf64855-cc40-403d-9816-90868a01604e",
   "metadata": {},
   "source": [
    "Define the Percepts class to hold the different percepts the Agent can sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df8bd139-09e4-4829-a65d-322274875e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PerceptsC.py\n",
    "\n",
    "class PerceptsC():\n",
    "\n",
    "    # Constructor\n",
    "\n",
    "    def __init__(self, stench=False, breeze=False, glitter=False, bump=False, scream=False, move=(), direction=None):\n",
    "\n",
    "        # Set object attributes.\n",
    "\n",
    "        self.stench = stench\n",
    "        self.breeze = breeze\n",
    "        self.glitter = glitter\n",
    "        self.bump = bump\n",
    "        self.scream = scream\n",
    "        self.move = move\n",
    "        self.direction = direction\n",
    "\n",
    "\n",
    "    # Getters and Setters.\n",
    "\n",
    "    def get_stench(self) -> bool:\n",
    "        return self.stench \n",
    "\n",
    "    def set_stench(self, stench):\n",
    "        self.stench = stench\n",
    "\n",
    "    def get_breeze(self) -> bool:\n",
    "        return self.breeze \n",
    "\n",
    "    def set_breeze(self, breeze):\n",
    "        self.breeze = breeze \n",
    "\n",
    "    def get_glitter(self) -> bool:\n",
    "        return self.glitter\n",
    "\n",
    "    def set_glitter(self, glitter):\n",
    "        self.glitter = glitter \n",
    "\n",
    "    def get_bump(self) -> bool:\n",
    "        return self.bump\n",
    "\n",
    "    def set_bump(self, bump):\n",
    "        self.bump = bump\n",
    "\n",
    "    def get_scream(self) -> bool:\n",
    "        return self.scream\n",
    "\n",
    "    def set_scream(self, scream):\n",
    "        self.scream = scream\n",
    "\n",
    "\n",
    "    def get_move(self) -> tuple([int, int]):\n",
    "        return self.move\n",
    "\n",
    "    def set_move(self, move):\n",
    "        self.move = move\n",
    "\n",
    "    def get_direction(self) -> str:\n",
    "        return self.direction\n",
    "\n",
    "    def set_direction(self, direction):\n",
    "        self.direction = direction\n",
    "\n",
    "\n",
    "    # print\n",
    "\n",
    "    def print(self):\n",
    "\n",
    "        # Add to the PerceptsC class\n",
    "\n",
    "        percepts_list = []\n",
    "\n",
    "        if (self.get_stench()):\n",
    "            percepts_list.append(\"Stench\")\n",
    "\n",
    "        if (self.get_breeze()):\n",
    "            percepts_list.append(\"Breeze\")\n",
    "\n",
    "        if (self.get_glitter()):\n",
    "            percepts_list.append(\"Glitter\")\n",
    "\n",
    "        if (self.get_bump()):\n",
    "            percepts_list.append(\"Bump\")\n",
    "\n",
    "        if (self.get_scream()):\n",
    "            percepts_list.append(\"Scream\")\n",
    "\n",
    "        if (self.get_move()):\n",
    "            percepts_list.append(\"Move\")\n",
    "\n",
    "        if (self.get_direction()):\n",
    "            percepts_list.append(\"Direction\")\n",
    "\n",
    "        print (percepts_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf89dd9-d3d9-41a8-8acb-04ada43c5511",
   "metadata": {},
   "source": [
    "Define the Abstract Agent class that will be the abstract super class of the Naive Agent, the Move Planning Agent and a future, smarter Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7156ea-4cbb-4c3e-91e1-faffdb7d2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgentA.py\n",
    "\n",
    "# Import libraries.\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class AgentA(ABC):\n",
    "\n",
    "\n",
    "    # Constructor.\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Do nothing.\n",
    "\n",
    "        self.percepts = None\n",
    "\n",
    "\n",
    "    # print_percepts\n",
    "\n",
    "    def print_percepts(self):\n",
    "\n",
    "        # Print out the percepts.\n",
    "\n",
    "        print (\"Percepts:\\t\", end='')\n",
    "        self.percepts.print()\n",
    "\n",
    "\n",
    "    # percept\n",
    "\n",
    "    @abstractmethod\n",
    "    def percept(self, percepts):\n",
    "\n",
    "        self.percepts = percepts\n",
    "\n",
    "    \n",
    "    # action\n",
    "\n",
    "    @abstractmethod\n",
    "    def action(self) -> str:\n",
    "\n",
    "        # Implement an algorithm for selecting an action to take based on the percepts.\n",
    "        \n",
    "        # Return nil for the abstract class.\n",
    "        \n",
    "        return nil\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a1cc9-fcec-49c9-acec-826f93a918c7",
   "metadata": {},
   "source": [
    "Define the Naive Agent class that is a concrete sub-class of the Agent abstract class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b6971a0-5580-4426-b620-d4625ba7f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaiveAgentC.py\n",
    "\n",
    "# Import libraries.\n",
    "\n",
    "import random\n",
    "\n",
    "class NaiveAgentC(AgentA):\n",
    "    \n",
    "    # percept\n",
    "\n",
    "    def percept(self, percepts):\n",
    "\n",
    "        # For the Naive Agent that isn't using Percepts, just\n",
    "        # call the super class.\n",
    "\n",
    "        super().percept(percepts)\n",
    "\n",
    "        # Print the percepts.\n",
    "\n",
    "        if Global._display:\n",
    "            self.print_percepts()\n",
    "\n",
    "\n",
    "    # action\n",
    "\n",
    "    def action(self) -> str:\n",
    " \n",
    "        # For the Naive Agent, the percepts will be received but not used\n",
    "        # in selecting the action to take.  The algorithm for selecting the\n",
    "        # action to take is random.\n",
    "        \n",
    "        # Randomly select one of the possible actions from the action set.\n",
    "\n",
    "        agent_action = random.randint(0, 5)\n",
    "\n",
    "        if Global._display: print (\"Action:\\t\\t\\t\", Global._action_array[agent_action])\n",
    "        \n",
    "        # Return the randomly selected action.\n",
    "\n",
    "        return Global._action_array[agent_action]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faca44e-e156-4003-bdd0-d234dfc3b43e",
   "metadata": {},
   "source": [
    "Define the Move Planning Agent class that is a concrete sub-class of the Agent abstract class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e699d04-5166-4c7b-a82a-ee3896bdcf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MovePlanningAgentC.py\n",
    "\n",
    "# Import libraries.\n",
    "\n",
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "class MovePlanningAgentC(AgentA):\n",
    "    \n",
    "    # Constructor.\n",
    "\n",
    "    def __init__(self, location):\n",
    "\n",
    "        # Set the state for having the Gold and its location.\n",
    "\n",
    "        # The Agent should only be notified of its original location and can update it as it\n",
    "        # builds the graph.\n",
    "\n",
    "        self.has_gold  = False\n",
    "        self.location  = location\n",
    "        self.direction = Global._east\n",
    "        self.exit_plan = []\n",
    "\n",
    "        # Add the initial location as the root of the path tree.\n",
    "\n",
    "        self.G = nx.DiGraph()\n",
    "        self._create_start_node_in_graph(self.location, self.direction)\n",
    "        \n",
    "\n",
    "    # percept\n",
    "\n",
    "    def percept(self, percepts):\n",
    "\n",
    "        # For the Move Planning Agent, it will use the Percepts for grabbing the gold and\n",
    "        # climbing out of the cave.  As it also uses the Percepts for detecting a Bump when\n",
    "        # trying to go out of bounds, it will also use the Percepts to detect that a valid\n",
    "        # move has been made.\n",
    "\n",
    "        # Call the super class to register the percepts.\n",
    "\n",
    "        super().percept(percepts)\n",
    "\n",
    "        new_location = self.percepts.get_move()\n",
    "        direction    = self.percepts.get_direction()\n",
    "\n",
    "        # Determine if a move has been made.\n",
    "\n",
    "        if (len(new_location) != 0):\n",
    "\n",
    "            # A move has been made, add the new node to the graph.\n",
    "                    \n",
    "            if Global._display: print (\"Action Result:\\t\\tLooking to add\", new_location, \"facing\", direction, \"(and other directions) to the visited room graph.\")\n",
    "\n",
    "            self._add_node_to_graph(self.location, new_location, direction)\n",
    "            \n",
    "            # Update the Agent's location and direction.\n",
    "\n",
    "            self.location  = new_location\n",
    "            self.direction = direction\n",
    "\n",
    "        # Print the percepts.\n",
    "\n",
    "        if Global._display: self.print_percepts()\n",
    "\n",
    "\n",
    "    # action\n",
    "\n",
    "    def action(self) -> str:\n",
    " \n",
    "        action = None\n",
    "\n",
    "        # The Agent is either exploring, looking for the Gold or the Agent has\n",
    "        # found it and is executing on its exit plan.\n",
    "\n",
    "        # Determine if the Agent is exploring or executing its exit plan.\n",
    "\n",
    "        if (len(self.exit_plan) > 0):\n",
    "\n",
    "            # The Agent is executing its exit plan.  Therefore, get the next\n",
    "            # action in the plan.\n",
    "\n",
    "            if Global._display: print (\"Status:\\t\\t\\t*** Agent is currently executing its exit plan...\")\n",
    "\n",
    "            if Global._display: print (\"Exit plan:\\t\\t\\t\", self.exit_plan)\n",
    "\n",
    "            # Get the next action to take.\n",
    "\n",
    "            action = self.exit_plan[0]\n",
    "\n",
    "            if Global._display: print (\"Action from Exit plan:\\t\\t\", action)\n",
    "\n",
    "            # Remove the action from the exit plan.\n",
    "\n",
    "            self.exit_plan.pop(0)\n",
    "\n",
    "            if Global._display: print (\"Exit plan after action:\\t\\t\", self.exit_plan)\n",
    "\n",
    "        \n",
    "        else:\n",
    "\n",
    "            # For the Move Planning Agent, use its sensors to read the percepts to see if the gold \n",
    "            # is in the current room or if they can climb out the cave with the gold.\n",
    "\n",
    "            if Global._display: print (\"Status:\\t\\t\\t*** Agent is currently exploring looking for Gold...\")\n",
    "\n",
    "            if (self.percepts.get_glitter()) and (self.has_gold == False):\n",
    "\n",
    "                if Global._display: print (\"Status:\\t\\t\\t*** Agent has detected the Gold and will now grab it...\")\n",
    "    \n",
    "                # Glitter has been sensed.  Action the Grab.\n",
    "\n",
    "                action = Global._grab_action\n",
    "\n",
    "                # Update the Agent's gold attribute.\n",
    "\n",
    "                self.has_gold = True\n",
    "\n",
    "                # Create the Exit plan that will be actioned the next time the Agent needs\n",
    "                # to action.\n",
    "\n",
    "                self.exit_plan = self._create_exit_plan(self.location, (1, 1), self.direction)\n",
    "\n",
    "            elif (self.location == Global._start_room) and (self.has_gold == True):\n",
    "\n",
    "                # The climb action is handled via the Agent's exit plan and the environment.\n",
    "\n",
    "                action = Global._climb_action\n",
    "\n",
    "            else:\n",
    "      \n",
    "                # Randomly select one of the possible actions from the action set (minus\n",
    "                # Grab and Climb).\n",
    "\n",
    "                agent_action = random.randint(0, 3)\n",
    "\n",
    "                if Global._display: print (\"Action:\\t\\t\\t\", Global._action_array[agent_action])\n",
    "        \n",
    "                action = Global._action_array[agent_action]\n",
    "\n",
    "        # Return the selected action.\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "    # Protected methods.\n",
    "\n",
    "\n",
    "    # _create_start_node_in_graph\n",
    "    \n",
    "    def _create_start_node_in_graph(self, start_node, direction):\n",
    "\n",
    "        # The start node is the special case - both the current and new nodes will be the\n",
    "        # same start node.\n",
    "\n",
    "        self._add_node_to_graph(start_node, start_node, direction)\n",
    "\n",
    "\n",
    "    # _add_node_to_graph\n",
    "\n",
    "    def _add_node_to_graph(self, current_node, new_node, direction):\n",
    "\n",
    "        # Add four nodes to the graph, one for each direction the Agent\n",
    "        # can face - north, east, south and west.\n",
    "\n",
    "        node_north = str(new_node) + \"-\" + Global._north\n",
    "        node_south = str(new_node) + \"-\" + Global._south\n",
    "        node_east  = str(new_node) + \"-\" + Global._east\n",
    "        node_west  = str(new_node) + \"-\" + Global._west\n",
    "\n",
    "        self.G.add_node(node_north, node=new_node, direction=Global._north)\n",
    "        self.G.add_node(node_south, node=new_node, direction=Global._south)\n",
    "        self.G.add_node(node_east,  node=new_node, direction=Global._east)\n",
    "        self.G.add_node(node_west,  node=new_node, direction=Global._west)\n",
    "\n",
    "        # Add the edges between the nodes and the action that would get you there.\n",
    "\n",
    "        self.G.add_edge(node_north, node_west,  action=Global._turnLeft_action)\n",
    "        self.G.add_edge(node_north, node_east,  action=Global._turnRight_action)\n",
    "        self.G.add_edge(node_east,  node_north, action=Global._turnLeft_action)\n",
    "        self.G.add_edge(node_east,  node_south, action=Global._turnRight_action)\n",
    "        self.G.add_edge(node_south, node_east,  action=Global._turnLeft_action)\n",
    "        self.G.add_edge(node_south, node_west,  action=Global._turnRight_action)\n",
    "        self.G.add_edge(node_west,  node_south, action=Global._turnLeft_action)\n",
    "        self.G.add_edge(node_west,  node_north, action=Global._turnRight_action)\n",
    "\n",
    "        # Adding the Forward edges if there are two different nodes (i.e., not the\n",
    "        # initial start node).\n",
    "\n",
    "        if (current_node != new_node):\n",
    "\n",
    "            # Add the Forward direction.  The direction of the node will point\n",
    "            # to the same direction of the new node and the opposite will be true.\n",
    "            # e.g., (1,1)-East will have an edge with (2,1)-East and (2,1)-West will\n",
    "            # have an edge with (1,1)-West.\n",
    "\n",
    "            current_north = str(current_node) + \"-\" + Global._north\n",
    "            current_south = str(current_node) + \"-\" + Global._south\n",
    "            current_east  = str(current_node) + \"-\" + Global._east\n",
    "            current_west  = str(current_node) + \"-\" + Global._west\n",
    "\n",
    "            # Determine the current direction and add the edges as indicated above in\n",
    "            # the comment.\n",
    "\n",
    "            if (direction == Global._north):\n",
    "                self.G.add_edge(current_north,  node_north,  action=Global._forward_action)\n",
    "                self.G.add_edge(node_south,  current_south,  action=Global._forward_action)\n",
    "            elif (direction == Global._east):\n",
    "                self.G.add_edge(current_east,  node_east,  action=Global._forward_action)\n",
    "                self.G.add_edge(node_west,  current_west,  action=Global._forward_action)\n",
    "            elif (direction == Global._south):\n",
    "                self.G.add_edge(current_south,  node_south,  action=Global._forward_action)\n",
    "                self.G.add_edge(node_north,  current_north,  action=Global._forward_action)\n",
    "            elif (direction == Global._west):\n",
    "                self.G.add_edge(current_west,  node_west,  action=Global._forward_action)\n",
    "                self.G.add_edge(node_east,  current_east,  action=Global._forward_action)\n",
    "\n",
    "\n",
    "        if Global._debug: print (\"\\nNodes:\", self.G.nodes)\n",
    "        if Global._debug: print (\"\\nEdges:\", self.G.edges)\n",
    "\n",
    "\n",
    "    # _create_exit_plan\n",
    "\n",
    "    def _create_exit_plan(self, source, dest, direction):\n",
    "        \n",
    "        source_node = str(source) + \"-\" + direction\n",
    "        dest_node = str(dest) + \"-\" + Global._east\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\tAgent is creating an exit plan from\", source_node, \"to\", dest)\n",
    "\n",
    "        if Global._debug:   print (\"Status:\\t\\t\\tAgent shortest Dijkstra path:\", nx.shortest_path(self.G, source_node, dest_node, weight=None, method='dijkstra'))\n",
    "        if Global._display: print (\"Status:\\t\\t\\tAgent Shortest A* path:\", nx.astar_path(self.G, source_node, dest_node, heuristic=None, weight='manhattan_distance'))\n",
    "\n",
    "        short_path = nx.astar_path(self.G, source_node, dest_node, heuristic=None, weight='manhattan_distance')\n",
    "\n",
    "        # Print out the nodes if in debug mode.\n",
    "\n",
    "        if Global._debug:\n",
    "\n",
    "            for node in short_path:\n",
    "\n",
    "                print (self.G.nodes[node][\"node\"], \" \", self.G.nodes[node][\"direction\"])\n",
    "\n",
    "        # The Agent only has to reach (1,1) in order to climb out,  Therefore, remove all\n",
    "        # other nodes past the first (1,1) in the path.\n",
    "\n",
    "        first_home_node = next(filter(lambda node: \"(1, 1)\" in node, short_path), None)\n",
    "\n",
    "        first_home_node_idx = short_path.index(first_home_node)\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\tIndex of (1,1) is: \", first_home_node, \"at node\", first_home_node_idx, \"in the path.\")\n",
    "\n",
    "        new_short_path = short_path[:first_home_node_idx+1]\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\tAgent new short path =\", new_short_path)\n",
    "\n",
    "        # Build the edges from the path.\n",
    "\n",
    "        path_edges = []\n",
    "    \n",
    "        for i in range(len(new_short_path) - 1):\n",
    "\n",
    "            # Get the current and new nodes.\n",
    "\n",
    "            node1 = new_short_path[i]\n",
    "            node2 = new_short_path[i+1]\n",
    "\n",
    "            # Add the edge.\n",
    "\n",
    "            path_edges.append((node1, node2))\n",
    "\n",
    "        action_plan = []\n",
    "\n",
    "        # Iterate through the edges to build the action plan by finding the edge in the graph's\n",
    "        # set of edges and getting the associated \"action\" with that particular edge.\n",
    "        #\n",
    "        # As this is a directed graph, and when we added the next set of nodes the directions between\n",
    "        # the nodes were bi-directional (e.g., North-West = Left and West-North = Right), the\n",
    "        # action associated with that edge will be the correct action to take to traverse that edge\n",
    "        # from the current node to the next node in the edge pair.\n",
    "\n",
    "        for edge in path_edges:\n",
    "            if Global._debug: print (edge, \" \", self.G.edges[edge][\"action\"])\n",
    "            action_plan.append(self.G.edges[edge][\"action\"])\n",
    "\n",
    "        # Finally, append the Climb action.\n",
    "\n",
    "        action_plan.append(Global._climb_action)\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\t*** The Agent's exit plan is:\", action_plan)\n",
    "\n",
    "        return action_plan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490c8c6-db84-46ff-b280-c654e4d70719",
   "metadata": {},
   "source": [
    "Define the Predicate Helper class for the Probability Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "500f7f20-0dc9-440d-881a-e3f5b8c52f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PredicateC\n",
    "#\n",
    "# Courtesy of Larry Simon\n",
    "\n",
    "from pomegranate.distributions import Categorical\n",
    "from pomegranate.distributions import ConditionalCategorical\n",
    "from pomegranate.bayesian_network import BayesianNetwork\n",
    "\n",
    "class PredicateC():   \n",
    "    def __init__(self, prob: float):\n",
    "        self.p = prob\n",
    "        \n",
    "    def toList(self):\n",
    "        return [1-self.p, self.p]\n",
    "        \n",
    "    def toCategorical(self):\n",
    "        return Categorical([self.toList()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d15b59-29ce-4f03-814b-8fe53aa9a8dd",
   "metadata": {},
   "source": [
    "Define the Probability Agent class that is a concrete sub-class of the Move Planning Agent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ad7827-725e-4f71-95cc-ef2f39003a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProbAgentC\n",
    "\n",
    "# Import libraries.\n",
    "\n",
    "import random\n",
    "import networkx as nx\n",
    "import math\n",
    "import torch\n",
    "from torch._prims_common import Tensor\n",
    "from pomegranate.distributions import Categorical\n",
    "from pomegranate.distributions import ConditionalCategorical\n",
    "from pomegranate.bayesian_network import BayesianNetwork\n",
    "import numpy\n",
    "\n",
    "\n",
    "class ProbAgentC(MovePlanningAgentC):\n",
    "\n",
    "    # Constructor\n",
    "\n",
    "    def __init__(self, location):\n",
    "\n",
    "        # Invoke the super class.\n",
    "\n",
    "        super().__init__(location)\n",
    "        \n",
    "        # Initialize the variables.\n",
    "\n",
    "        self.has_arrow = True\n",
    "        self.move_plan = []\n",
    "        self.path_taken = []\n",
    "        self.rooms_dict = {}\n",
    "\n",
    "        # Build the model.\n",
    "\n",
    "        self._build_model()\n",
    "\n",
    "\n",
    "\n",
    "    # percept\n",
    "\n",
    "    def percept(self, percepts):\n",
    "\n",
    "        # For the Probability Agent, it will use the Percepts for grabbing the gold and\n",
    "        # climbing out of the cave.  As it also uses the Percepts for detecting a Bump when\n",
    "        # trying to go out of bounds, it will also use the Percepts to detect that a valid\n",
    "        # move has been made.  It also uses it to detect screams.\n",
    "\n",
    "        # Call the super class to register the percepts.\n",
    "\n",
    "        super().percept(percepts)\n",
    "\n",
    "        new_location = self.percepts.get_move()\n",
    "        direction    = self.percepts.get_direction()\n",
    "\n",
    "        # Determine if a scream has been heard from the wumpus.\n",
    "\n",
    "        if (self.percepts.get_scream()):\n",
    "\n",
    "            # A scream has been heard.\n",
    "\n",
    "            if Global._display: print (\"Status:\\t\\t\\t*** Agent has detected the Scream from a dead Wumpus.  Setting Wumpus probability to 0..\")\n",
    "\n",
    "            # As the Wumpus is dead, the probability of dying from the Wumpus is now 0.\n",
    "            # Update the Wumpus predicates and Wumpus list.\n",
    "\n",
    "            new_prob = 0\n",
    "            wumpus_categorical = PredicateC(new_prob).toCategorical()\n",
    "\n",
    "            # Iterate over rooms and set the new probability info.\n",
    "\n",
    "            for room_key in self.rooms_dict.keys():\n",
    "\n",
    "                self.wumpus_predicate_list[room_key] = wumpus_categorical\n",
    "                self.wumpus_list[room_key] = 0\n",
    "\n",
    "        # Determine if a move has been made.\n",
    "\n",
    "        if (len(new_location) != 0):\n",
    "\n",
    "            # A move has been made, add the new node to the graph.\n",
    "                    \n",
    "            if Global._display: print (\"Action Result:\\t\\tLooking to add\", new_location, \"facing\", direction, \"(and other directions) to the visited room graph.\")\n",
    "\n",
    "            self._add_node_to_graph(self.location, new_location, direction)\n",
    "            \n",
    "            # Update the Agent's location and direction.\n",
    "\n",
    "            self.location  = new_location\n",
    "            self.direction = direction\n",
    "\n",
    "            # The graph node is in the form (1, 1).  Convert it into a dictionary lookup value \"1-1\".\n",
    "\n",
    "            current_room = str(self.location[0]) + \"-\" + str(self.location[1])\n",
    "\n",
    "            # If the Agent got to this point, the Agent is still alive so this room is neither a pit\n",
    "            # or the location of the Wumpus.\n",
    "\n",
    "            self.pit_list[current_room] = 0\n",
    "            self.wumpus_list[current_room] = 0\n",
    "\n",
    "            # As the Wumpus has an original 1/15 probability of being in a room, if this room\n",
    "            # does not have the Wumpus then the probability of the other rooms having the Wumpus\n",
    "            # increases.\n",
    "\n",
    "            # Count how many rooms already have been determined to not contain the Wumpus.\n",
    "\n",
    "            wumpus_free_room_count = 0\n",
    "\n",
    "            for wumpus_room in self.wumpus_list.keys():\n",
    "\n",
    "                # If the room was already Wumpus-free, add it to the count.\n",
    "\n",
    "                if (self.wumpus_list[wumpus_room] == 0):\n",
    "\n",
    "                    wumpus_free_room_count = wumpus_free_room_count + 1\n",
    "\n",
    "            # Calculate the new probability for the Wumpus.\n",
    "\n",
    "            new_wumpus_prob = 1/(15 - wumpus_free_room_count) if wumpus_free_room_count < 15 else 0\n",
    "            if Global._display: print (\"Status:\\t\\t\\t*** Agent has calculated the new Wumpus probability for each unknown room as\", new_wumpus_prob)\n",
    "\n",
    "            # Iterate over the rooms and update the Wumpus predicate and probability info.\n",
    "\n",
    "            for room_key in self.rooms_dict.keys():\n",
    "\n",
    "                # Update the Wumpus room probability if the room is 'unknown'.  The other rooms\n",
    "                # would already have a 0 (e.g., 1-1).\n",
    "\n",
    "                if (self.wumpus_list[room_key] == -1):\n",
    "\n",
    "                    # Set the new probability.\n",
    "\n",
    "                    wumpus_categorical = PredicateC(new_wumpus_prob).toCategorical()\n",
    "                    self.wumpus_predicate_list[room_key] = wumpus_categorical\n",
    "\n",
    "\n",
    "            # Finally, add this room to the path taken.\n",
    "\n",
    "            self.path_taken.append(current_room)\n",
    "\n",
    "\n",
    "    # action\n",
    "\n",
    "    def action(self) -> str:\n",
    " \n",
    "        action = None\n",
    "\n",
    "        # The Agent is either exploring, looking for the Gold or the Agent has\n",
    "        # found it and is executing on its exit plan.\n",
    "\n",
    "        # Determine if the Agent is exploring or executing its exit plan.\n",
    "\n",
    "        if (len(self.exit_plan) > 0):\n",
    "\n",
    "            # The Agent is executing its exit plan.  Therefore, get the next\n",
    "            # action in the plan.\n",
    "\n",
    "            if Global._display: print (\"Status:\\t\\t\\t*** Agent is currently executing its exit plan...\")\n",
    "\n",
    "            if Global._display: print (\"Exit plan:\\t\\t\\t\", self.exit_plan)\n",
    "\n",
    "            # Get the next action to take.\n",
    "\n",
    "            action = self.exit_plan[0]\n",
    "\n",
    "            if Global._display: print (\"Action from Exit plan:\\t\\t\", action)\n",
    "\n",
    "            # Remove the action from the exit plan.\n",
    "\n",
    "            self.exit_plan.pop(0)\n",
    "\n",
    "            if Global._display: print (\"Exit plan after action:\\t\\t\", self.exit_plan)\n",
    "\n",
    "\n",
    "        elif (len(self.move_plan) > 0):\n",
    "\n",
    "            # The Agent is executing its move plan to get to the next best node.  Therefore, get the next\n",
    "            # action in the plan.\n",
    "\n",
    "            if Global._display: print (\"Status:\\t\\t\\t*** Agent is currently in a movement plan...\")\n",
    "\n",
    "            if Global._display: print (\"Move plan:\\t\\t\\t\", self.move_plan)\n",
    "\n",
    "            # Get the next action to take.\n",
    "\n",
    "            action = self.move_plan[0]\n",
    "\n",
    "            if Global._display: print (\"Action from Move plan:\\t\\t\", action)\n",
    "\n",
    "            # Remove the action from the exit plan.\n",
    "\n",
    "            self.move_plan.pop(0)\n",
    "\n",
    "            if Global._display: print (\"Move plan after action:\\t\\t\", self.move_plan)\n",
    "\n",
    "        \n",
    "        else:\n",
    "\n",
    "            # For the Probability Agent, use its sensors to read the percepts to see if the gold \n",
    "            # is in the current room or if they can climb out the cave with the gold. Otherwise, if it \n",
    "            # detects a stench, fire the arrow (if it still has it) or look for the next best room to move into.\n",
    "\n",
    "            if Global._display: print (\"Status:\\t\\t\\t*** Agent is currently exploring looking for Gold...\")\n",
    "\n",
    "            if (self.percepts.get_glitter()) and (self.has_gold == False):\n",
    "\n",
    "                if Global._display: print (\"Status:\\t\\t\\t*** Agent has detected the Gold and will now grab it...\")\n",
    "    \n",
    "                # Glitter has been sensed.  Action the Grab.\n",
    "\n",
    "                action = Global._grab_action\n",
    "\n",
    "                # Update the Agent's gold attribute.\n",
    "\n",
    "                self.has_gold = True\n",
    "\n",
    "                # Create the Exit plan that will be actioned the next time the Agent needs\n",
    "                # to action.\n",
    "\n",
    "                self.exit_plan = self._create_exit_plan(self.location, (1, 1), self.direction)\n",
    "\n",
    "            elif (self.location == Global._start_room) and (self.has_gold == True):\n",
    "\n",
    "                # The climb action is handled via the Agent's exit plan and the environment.\n",
    "\n",
    "                action = Global._climb_action\n",
    "\n",
    "            elif ((self.percepts.get_stench()) and (self.has_arrow == True)):\n",
    "\n",
    "                # Stench has been detected and we have the arrow.  May as well give it a shot.\n",
    "\n",
    "                action = Global._shoot_action\n",
    "                self.has_arrow = False\n",
    "\n",
    "            else:\n",
    "      \n",
    "                # Move Action.  First, identify the Agent location and direction.\n",
    "\n",
    "                if Global._display: print (\"Status:\\t\\t\\t*** Agent is looking to move...\")\n",
    "\n",
    "                # The graph node is in the form (1, 1).  Convert it into a dictionary lookup value \"1-1\".\n",
    "\n",
    "                current_room = str(self.location[0]) + \"-\" + str(self.location[1])\n",
    "\n",
    "                # See if this is a Breeze room based on the Percepts.\n",
    "\n",
    "                self.breeze_list[current_room] = 1 if (self.percepts.get_breeze()) else 0\n",
    "\n",
    "                # See if this is a Stench room based on the Percepts.\n",
    "\n",
    "                self.stench_list[current_room] = 1 if (self.percepts.get_stench()) else 0\n",
    "\n",
    "                # Get the possible move options based on the possibility that the next room is a pit or the Wumpus.\n",
    "\n",
    "                if Global._display: print (\"Status:\\t\\t\\t*** Agent is looking to see which move can avoid a pit...\")\n",
    "                pit_move_options = self._get_move_options_to_avoid_pit(current_room)\n",
    "\n",
    "                if Global._display: print (\"Status:\\t\\t\\t*** Agent is looking to see which move can avoid the Wumpus...\")\n",
    "                wumpus_move_options = self._get_move_options_to_avoid_wumpus(current_room)\n",
    "\n",
    "                # Now get the best room option based on the probabilities calculated above that the neighbour rooms\n",
    "                # to which the Agent can move contains a pit or the Wumpus.\n",
    "\n",
    "                best_room_option = self._choose_best_move_option(current_room, pit_move_options, wumpus_move_options, self.direction)\n",
    "             \n",
    "                if Global._display: print (\"Status:\\t\\t\\t*** The best room for the Agent to move to is\", best_room_option)\n",
    "\n",
    "                # If the best room option is Exit, the Agent has determined that it is too dangerous to move as the\n",
    "                # probability of dying is > 50 %.  Exit out of the cave.\n",
    "\n",
    "                if (best_room_option == 'Exit'):\n",
    "\n",
    "                    if Global._display: print (\"Status:\\t\\t\\t*** Next moves have been deemed too dangerous.  Agent is bailing.\")\n",
    "\n",
    "                    # Do one final grab just in case!\n",
    "\n",
    "                    action = Global._grab_action\n",
    "\n",
    "                    # Create the Exit plan that will be actioned the next time the Agent needs\n",
    "                    # to action.\n",
    "\n",
    "                    self.exit_plan = self._create_exit_plan(self.location, (1, 1), self.direction)\n",
    "                \n",
    "                else:\n",
    "\n",
    "                    # Get the move plan and execute it.  The move plan will be something like [\"TurnLeft\", \"Forward\"].\n",
    "\n",
    "                    self.move_plan = self._get_move_plan(current_room, best_room_option, self.direction)\n",
    "\n",
    "                    if Global._display: print (\"Status:\\t\\t\\t*** The Agent's move plan is\", self.move_plan)\n",
    "\n",
    "                    # Get the first action to take.\n",
    "\n",
    "                    action = self.move_plan.pop(0)\n",
    "\n",
    "\n",
    "        # Return the selected action.\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "    # Private Methods\n",
    "\n",
    "    # _build_model\n",
    "\n",
    "    def _build_model(self):\n",
    "\n",
    "        # Build the neighbours model.\n",
    "\n",
    "        # Iterate over the x-grid.\n",
    "\n",
    "        for i in range (1,5):\n",
    "\n",
    "            # Iterate over the y-grid.\n",
    "\n",
    "            for j in range (1,5):\n",
    "\n",
    "                # Identify the current room's neighboours and add them to the set.\n",
    "\n",
    "                neighbours = []\n",
    "\n",
    "                if ((i-1) > 0):\n",
    "                    west_neighbour = str(i-1) + \"-\" + str(j)\n",
    "                    neighbours.append(west_neighbour)\n",
    "\n",
    "                if ((i+1) < 5):\n",
    "                    east_neighbour = str(i+1) + \"-\" + str(j)\n",
    "                    neighbours.append(east_neighbour)\n",
    "\n",
    "                if ((j+1) < 5):\n",
    "                    north_neighbour = str(i) + \"-\" + str(j+1)\n",
    "                    neighbours.append(north_neighbour)\n",
    "\n",
    "                if ((j-1) > 0):\n",
    "                    south_neighbour = str(i) + \"-\" + str(j-1)\n",
    "                    neighbours.append(south_neighbour)\n",
    "\n",
    "                if Global._debug: print (\"Status:\\t\\t\\t*** The Agent's neighbours at (\", i, \",\", j, \") -> \", neighbours)\n",
    "\n",
    "                # Construct the room key and add it and the neighbours to the room dictionary.\n",
    "\n",
    "                my_key = str(i) + \"-\" + str(j)\n",
    "\n",
    "                self.rooms_dict[my_key] = neighbours\n",
    "\n",
    "        # Print the rooms dictionary.\n",
    "\n",
    "        if Global._debug: print (\"Status:\\t\\t\\t*** The Agent's room dictionary is:\", self.rooms_dict)\n",
    "\n",
    "        # Now that the set of rooms and each room's neighbours has been constructed, set all\n",
    "        # rooms to be the standard 20% probability that the room could be a pit (before any\n",
    "        # evidence is gathered).\n",
    "\n",
    "        self.pit_predicate_list = {}\n",
    "        pit_categorical = PredicateC(0.2).toCategorical()\n",
    "        \n",
    "        # All of the rooms, except for 1-1, can be a pit.  Therefore, create a pit list of all\n",
    "        # the rooms and set them to be -1 (unknown).  These will be updated as the Agent gathers\n",
    "        # more information about the cave and which rooms are safe.\n",
    "\n",
    "        self.pit_list = {}\n",
    "        pit_unknown = -1\n",
    "\n",
    "        # Keep a list of all rooms that have a breeze.\n",
    "\n",
    "        self.breeze_list = {}\n",
    "        breeze_unknown = -1\n",
    "\n",
    "        # Add the Wumpus model. To start, the probability of the Wumpus being in a room is 1/15 (the Wumpus\n",
    "        # can't be in the start room).  However, as the cave is explored, the probability of the Wumpus being\n",
    "        # in each future room increases.\n",
    "\n",
    "        self.wumpus_predicate_list = {}\n",
    "        wumpus_categorical = PredicateC(1/15).toCategorical() \n",
    "\n",
    "        self.wumpus_list = {}\n",
    "        wumpus_unknown = -1\n",
    "\n",
    "        # Add the Stench model.\n",
    "\n",
    "        self.stench_list = {}\n",
    "        stench_unknown = -1\n",
    "\n",
    "        # Iterate over the room keys which will include all rooms in the cave.\n",
    "        # Create the categorical probability for the dictionary\n",
    "        # Set each room to be unknown for a pit and unknown for a breeze.\n",
    "\n",
    "        for room_key in self.rooms_dict.keys():\n",
    "\n",
    "            # Pit and breeze info.  NOTE: don't need separate unknowns for breeze, pit etc. as they are the same.\n",
    "\n",
    "            self.pit_predicate_list[room_key] = pit_categorical\n",
    "            self.pit_list[room_key]           = pit_unknown\n",
    "            self.breeze_list[room_key]        = breeze_unknown\n",
    "\n",
    "            # Wumpus and stench info.\n",
    "\n",
    "            self.wumpus_predicate_list[room_key] = wumpus_categorical\n",
    "            self.wumpus_list[room_key]           = wumpus_unknown\n",
    "            self.stench_list[room_key]           = stench_unknown\n",
    "\n",
    "\n",
    "        # Room 1-1 cannot be a pit or wumpus.  Therefore, it will be set to 0 (safe).\n",
    "\n",
    "        self.pit_list[\"1-1\"] = 0\n",
    "        self.wumpus_list[\"1-1\"] = 0\n",
    "\n",
    "        # Finally, add the starting room to the path taken.\n",
    "\n",
    "        self.path_taken.append(\"1-1\")\n",
    "\n",
    "\n",
    "    # _get_move_plan\n",
    "\n",
    "    def _get_move_plan(self, src_room, dest_room, direction):\n",
    "\n",
    "        move_plan = []\n",
    "\n",
    "        # Get the x, y coordinates of the source and destination rooms.\n",
    "\n",
    "        src_x = src_room[0]\n",
    "        src_y = src_room[2]\n",
    "\n",
    "        dest_x = dest_room[0]\n",
    "        dest_y = dest_room[2]\n",
    "\n",
    "        # Determine if the destination node is North, East, West or South \n",
    "        # from the source node.\n",
    "\n",
    "        if (dest_x < src_x):\n",
    "            destination = Global._west\n",
    "\n",
    "        elif (dest_x > src_x):\n",
    "            destination = Global._east\n",
    "\n",
    "        elif (dest_y < src_y):\n",
    "            destination = Global._south\n",
    "\n",
    "        elif (dest_y > src_y):\n",
    "            destination = Global._north\n",
    "\n",
    "        # Now figure out how to turn to get there.\n",
    "\n",
    "        if (((direction == Global._east) and (destination == Global._north)) or\n",
    "            ((direction == Global._west) and (destination == Global._south)) or\n",
    "            ((direction == Global._south) and (destination == Global._east)) or\n",
    "            ((direction == Global._north) and (destination == Global._west))):\n",
    "\n",
    "            # These are the only directions and destinations where turning left\n",
    "            # is shorter.\n",
    "\n",
    "            move_plan.append(Global._turnLeft_action)\n",
    "        else:\n",
    "\n",
    "            # Might as well turn right.\n",
    "\n",
    "            while (direction != destination):\n",
    "\n",
    "                # Continue turning right and updating the direction until it matches the\n",
    "                # destination.\n",
    "\n",
    "                direction = self._turn_right(direction)\n",
    "                move_plan.append(Global._turnRight_action)\n",
    "\n",
    "        # Add the forward action to the plan.\n",
    "\n",
    "        move_plan.append(Global._forward_action)\n",
    "\n",
    "        return move_plan \n",
    "\n",
    "\n",
    "    # _turn_right\n",
    "    \n",
    "    def _turn_right(self, direction):\n",
    "\n",
    "        # By turning right, return the new direction.\n",
    "\n",
    "        if (direction == Global._north):\n",
    "            return Global._east\n",
    "        elif (direction == Global._east):\n",
    "            return Global._south\n",
    "        elif (direction == Global._south):\n",
    "            return Global._west\n",
    "        elif (direction == Global._west):\n",
    "            return Global._north\n",
    "\n",
    "\n",
    "    # _choose_best_move_option\n",
    "            \n",
    "    def _choose_best_move_option(self, current_location, neighbour_prob_dict, wumpus_neighbour_prob_dict, direction):\n",
    "\n",
    "        # Set the best room variables.\n",
    "\n",
    "        best_false_value = 0\n",
    "        best_room_option = \"\"\n",
    "        best_room_options = []\n",
    "\n",
    "        # Iterate over the current room's neighbours.\n",
    "\n",
    "        for best_room in neighbour_prob_dict.keys():        # pit_neighbour and wumpus_neighbour are the same thing\n",
    "\n",
    "            # Get the True / False dictionary for this neighbour from the Pit network and extract the False value.\n",
    "            # The False value is the % that the room does not have a Pit or Wumpus (i.e., it would be\n",
    "            # True if it contained a pit or wumpus).\n",
    "\n",
    "            true_false_dict = neighbour_prob_dict[best_room]\n",
    "            false_value = true_false_dict[\"False\"]\n",
    "\n",
    "            # Get the True / False dictionary from the Wumpus network.\n",
    "\n",
    "            wumpus_true_false_dict = wumpus_neighbour_prob_dict[best_room]\n",
    "            wumpus_false_value = wumpus_true_false_dict[\"False\"]\n",
    "\n",
    "            if Global._display: print (\"Status:\\t\\t\\t*** Evaluating room\", best_room, \"the % that it is NOT a pit is\", false_value)\n",
    "            if Global._display: print (\"Status:\\t\\t\\t*** Evaluating room\", best_room, \"the % that it is NOT a wumpus is\", wumpus_false_value)\n",
    "\n",
    "            # Calculate the % that the room is a pit or wumpus. \n",
    "\n",
    "            not_a_pit_or_wumpus = false_value * wumpus_false_value\n",
    "\n",
    "            if Global._display: print (\"Status:\\t\\t\\t*** Evaluating room\", best_room, \"the % that it is NOT both is (1-p)(1-w)\", not_a_pit_or_wumpus)\n",
    "\n",
    "            # Sometimes, the % calculation from the Bayesian Network is not a number.  Convert it to 1.\n",
    "\n",
    "            is_nan = isinstance(not_a_pit_or_wumpus, float) and math.isnan(not_a_pit_or_wumpus)\n",
    "\n",
    "            if (is_nan):\n",
    "                not_a_pit_or_wumpus = 1\n",
    "                if Global._display: print (\"Status:\\t\\t\\t*** Converting room:\", best_room, \": the % that it is NOT both is (1-p)(1-w)\", not_a_pit_or_wumpus)\n",
    "\n",
    "            # Determine if the new % is greater or equal to the current best False value.\n",
    "\n",
    "            if (not_a_pit_or_wumpus >= best_false_value):\n",
    "\n",
    "                # Ensure that the best room is not in the path of rooms visited so that it doesn't go into\n",
    "                # an endless loop.  Always explore further!\n",
    "                #last_node = self.path_taken[-2] if (len(self.path_taken) > 1) else self.path_taken[-1]\n",
    "                #if ((best_room != last_node) and (len(self.path_taken) == 1)):\n",
    "\n",
    "               if (best_room not in (self.path_taken)):\n",
    "\n",
    "                    # If the combined % > Best False value.\n",
    "                    # Set the best room options to be just this room.\n",
    "\n",
    "                    if (not_a_pit_or_wumpus > best_false_value):\n",
    "                        best_room_options = [best_room] \n",
    "                    else:\n",
    "                        # If the combined % = Best False value.\n",
    "                        # Add this room to the set of best room options.\n",
    "\n",
    "                        best_room_options.append(best_room) \n",
    "\n",
    "                    # Set the new high watermark.\n",
    "\n",
    "                    best_false_value = not_a_pit_or_wumpus\n",
    "\n",
    "        # Check if there is a set of best rooms (e.g., tied with their False values).\n",
    "\n",
    "        if (len(best_room_options) > 1):\n",
    "\n",
    "            shortest_path = 100    # Make it large to start!\n",
    "\n",
    "            # Iterate over the best room options.\n",
    "\n",
    "            for candidate_option in best_room_options:\n",
    "\n",
    "                # Calculate the shortest path to get to that room.\n",
    "\n",
    "                path_len = self._calculate_shortest_path(current_location, candidate_option, direction)\n",
    "\n",
    "                if Global._display: print (\"Status:\\t\\t\\t*** Path Len from \", current_location, \"to\", candidate_option, \"while facing\", direction, \"is\", path_len)\n",
    "\n",
    "                # Check to see if this path length is the shortest path between the nodes.\n",
    "\n",
    "                if (path_len < shortest_path):\n",
    "                    shortest_path = path_len\n",
    "                    best_room_option = candidate_option\n",
    "\n",
    "        elif (len(best_room_options) == 1):\n",
    "\n",
    "            # There is only one best room in the set.  Just set it.\n",
    "\n",
    "            best_room_option = best_room_options[0]\n",
    "\n",
    "        else:\n",
    "\n",
    "            # There are no best rooms in the set - could be because of a Tensor computation where the\n",
    "            # value is NaN.  Therefore, just bail.\n",
    "\n",
    "            best_room_option = 'Exit'\n",
    "\n",
    "        # Determine if it is best if the Agent just leaves.  If the probability that the room is safe (i.e., False)\n",
    "        # is lower than the Agent Fear Index (e.g., 50%), it is best for the Agent to bail.\n",
    "\n",
    "        if (best_false_value < Global._agent_fear_index):\n",
    "\n",
    "            # Best for the Agent to leave.\n",
    "\n",
    "            best_room_option = 'Exit'\n",
    "\n",
    "        # Return the best room option.\n",
    "\n",
    "        return best_room_option\n",
    "\n",
    "    \n",
    "    # _calculate_shortest_path\n",
    "\n",
    "    def _calculate_shortest_path(self, source, dest, direction):\n",
    "\n",
    "        return len(self._get_move_plan(source, dest, direction))\n",
    "\n",
    "\n",
    "    # _create_neighbour_cases_for_room\n",
    "\n",
    "    def _create_neighbour_cases_for_room(self, current_room) -> []:\n",
    "\n",
    "        # Get the current room's neighbours.\n",
    "\n",
    "        current_room_neighbours = self.rooms_dict[current_room]\n",
    "        current_room_neighbours_count = len(current_room_neighbours)\n",
    "\n",
    "        # Based on the number of neighbours, create the cases.\n",
    "\n",
    "        if (current_room_neighbours_count == 2):\n",
    "\n",
    "            current_room_cases = self._create_cases_with_two_neighbours()\n",
    "\n",
    "        elif (current_room_neighbours_count == 3):\n",
    "\n",
    "            current_room_cases = self._create_cases_with_three_neighbours()\n",
    "\n",
    "        elif (current_room_neighbours_count == 4):\n",
    "\n",
    "            current_room_cases = self._create_cases_with_four_neighbours()\n",
    "\n",
    "        return current_room_cases\n",
    "\n",
    "\n",
    "    # _get_move_options_to_avoid_wumpus\n",
    "\n",
    "    def _get_move_options_to_avoid_wumpus(self, current_room):\n",
    "\n",
    "        # Get the neighbours for the current room.\n",
    "\n",
    "        current_room_neighbours = self.rooms_dict[current_room]\n",
    "\n",
    "        # Build the neighbour cases for the current room.\n",
    "\n",
    "        current_room_cases = self._create_neighbour_cases_for_room(current_room)\n",
    "\n",
    "        # Create the conditional categorical object now that we have the cases for the current room's neighbours.\n",
    "        \n",
    "        stench_condition_categorical = ConditionalCategorical([current_room_cases])\n",
    "\n",
    "        # Create the variables (stench room and its adjacent rooms) and the\n",
    "        # edges (an edge is from an adjacent room to the stench room).\n",
    "\n",
    "        variable_list        = []\n",
    "        edge_list            = []\n",
    "        room_and_stench_list = []\n",
    "\n",
    "        # Iterate over the current room's neighbours.\n",
    "\n",
    "        for current_room_neighbour in current_room_neighbours:\n",
    "\n",
    "            # If the stench has been detected, the Wumpus is in one of the neighbouring rooms.\n",
    "            # Therefore, update the probability.\n",
    "              \n",
    "            if (self.percepts.get_stench()):\n",
    "\n",
    "                # Update the probability.\n",
    "\n",
    "                if (self.wumpus_list[current_room_neighbour] != 0):\n",
    "\n",
    "                    # Calculate the new probability and set it.\n",
    "\n",
    "                    new_prob = 1/len(current_room_neighbours)\n",
    "                    wumpus_categorical = PredicateC(new_prob).toCategorical()\n",
    "                    self.wumpus_predicate_list[current_room_neighbour] = wumpus_categorical\n",
    "            \n",
    "            # Create the room predicate.\n",
    "\n",
    "            current_room_neighbour_predicate = self.wumpus_predicate_list[current_room_neighbour]\n",
    "            variable_list.append(current_room_neighbour_predicate)\n",
    "\n",
    "            # Create the edge.\n",
    "\n",
    "            edge_list.append((current_room_neighbour_predicate, stench_condition_categorical))\n",
    "\n",
    "            # Add the knowledge of if the neighbour is a wumpus to the tensor.\n",
    "            # -1 is unknown; 0 is safe; 1 is a pit\n",
    "\n",
    "            current_room_neighbour_wumpus_knowledge = self.wumpus_list[current_room_neighbour]\n",
    "            room_and_stench_list.append(current_room_neighbour_wumpus_knowledge)\n",
    "\n",
    "                \n",
    "        # If there is a stench, then the Wumpus is in one of the neighbouring rooms.\n",
    "        # Therefore, set the rest of the locations to 0 (no Wumpus) and the\n",
    "        # predicates to 0 (no chance of a Wumpus).\n",
    "        # Note that this only applies to the Wumpus since there is only one.  This can't\n",
    "        # be applied to the pits as there can be many.\n",
    "        \n",
    "        if (self.percepts.get_stench()):\n",
    "\n",
    "            # Iterate over the Wumpus list.\n",
    "\n",
    "            for room in self.wumpus_list.keys():\n",
    "\n",
    "                # Update the knowledge about which room can have the Wumpus.\n",
    "\n",
    "                if ((self.wumpus_list[room] == -1) and (room not in current_room_neighbours)):\n",
    "\n",
    "                    no_wumpus_categorical = PredicateC(0).toCategorical()\n",
    "                    self.wumpus_predicate_list[room] = no_wumpus_categorical\n",
    "                    self.wumpus_list[room] = 0\n",
    "\n",
    "        # Now add the predicate for the stench room at the end of the list.\n",
    "        # Add the stench knowledge - 0 if no stench is detected, 1 if a stench is detected.\n",
    "\n",
    "        stench_condition_knowledge = self.stench_list[current_room]  \n",
    "\n",
    "        variable_list.append(stench_condition_categorical)\n",
    "        room_and_stench_list.append(stench_condition_knowledge)\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\t*** Evaluating probability for the Wumpus - room and stench list\", room_and_stench_list)\n",
    "\n",
    "        # Run the Pomegranate model to get the neighbour rooms' probabilities.\n",
    "\n",
    "        neighbour_prob_dict = self._run_bayesian_network_model(current_room_neighbours, variable_list, edge_list, room_and_stench_list)\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\t*** Evaluating probability for the Wumpus - neighbour probabilities\", neighbour_prob_dict)\n",
    "\n",
    "        return neighbour_prob_dict\n",
    "\n",
    "\n",
    "    # _get_move_options_to_avoid_pit\n",
    "\n",
    "    def _get_move_options_to_avoid_pit(self, current_room):\n",
    "\n",
    "        # Get the neighbours for the current room.\n",
    "\n",
    "        current_room_neighbours = self.rooms_dict[current_room]\n",
    "\n",
    "        # Build the neighbour cases for the current room.\n",
    "\n",
    "        current_room_cases = self._create_neighbour_cases_for_room(current_room)\n",
    "\n",
    "        # Create the conditional categorical object now that we have the cases for the current room's neighbours.\n",
    "         \n",
    "        breeze_condition_categorical = ConditionalCategorical([current_room_cases])\n",
    "\n",
    "        # Create the variables (breeze room and its adjacent rooms) and the\n",
    "        # edges (an edge is from an adjacent room to the breeze room).\n",
    "\n",
    "        variable_list        = []\n",
    "        edge_list            = []\n",
    "        room_and_breeze_list = []\n",
    "\n",
    "        # Iterate over the current room's neighbours.\n",
    "\n",
    "        for current_room_neighbour in current_room_neighbours:\n",
    "\n",
    "            # If the breeze has been detected, a pit is in one of the neighbouring rooms.\n",
    "            # Therefore, update the probability.\n",
    "\n",
    "            if (self.percepts.get_breeze()):\n",
    "\n",
    "                # Update the probability.\n",
    "                \n",
    "                if (self.pit_list[current_room_neighbour] != 0):  # !!! NEW\n",
    "\n",
    "                    # Calculate the new probability and set it.\n",
    "\n",
    "                    new_prob = 1/len(current_room_neighbours)\n",
    "                    pit_categorical = PredicateC(new_prob).toCategorical()\n",
    "                    self.pit_predicate_list[current_room_neighbour] = pit_categorical\n",
    "      \n",
    "            # Create the room predicate.\n",
    "\n",
    "            current_room_neighbour_predicate = self.pit_predicate_list[current_room_neighbour]\n",
    "            variable_list.append(current_room_neighbour_predicate)\n",
    "\n",
    "            # Create the edge.\n",
    "\n",
    "            edge_list.append((current_room_neighbour_predicate, breeze_condition_categorical))\n",
    "\n",
    "            # Add the knowledge of if the neighbour is a pit to the tensor.\n",
    "            # -1 is unknown; 0 is safe; 1 is a pit\n",
    "\n",
    "            current_room_neighbour_pit_knowledge = self.pit_list[current_room_neighbour]\n",
    "            room_and_breeze_list.append(current_room_neighbour_pit_knowledge)\n",
    "\n",
    "        # Now add the predicate for the breeze room at the end of the list.\n",
    "        # Add the breeze knowledge - 0 if no breeze is detected, 1 if a breeze is detected.\n",
    "\n",
    "        breeze_condition_knowledge = self.breeze_list[current_room]  #1 # breeze is detected\n",
    "\n",
    "        variable_list.append(breeze_condition_categorical)\n",
    "        room_and_breeze_list.append(breeze_condition_knowledge)\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\t*** Evaluating probability for the pit - room and breeze list\", room_and_breeze_list)\n",
    "\n",
    "        # Run the Pomegranate model to get the neighbour rooms' probabilities.\n",
    "\n",
    "        neighbour_prob_dict = self._run_bayesian_network_model(current_room_neighbours, variable_list, edge_list, room_and_breeze_list)\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\t*** Evaluating probability for the pit - neighbour probabilities\", neighbour_prob_dict)\n",
    "\n",
    "        return neighbour_prob_dict\n",
    "\n",
    "\n",
    "    # _run_bayesian_network_model\n",
    "\n",
    "    def _run_bayesian_network_model(self, breeze_room_neighbours, variables, edges, room_and_breeze_list): \n",
    "\n",
    "        # Construct the model with the three variables, and two edges\n",
    "\n",
    "        # Display the variables and edges only if required during debugging.\n",
    "\n",
    "        #if Global._display: print (\"Status:\\t\\t\\t*** Running the BayesianNetwork model - variables:\", variables)\n",
    "        #if Global._display: print (\"Status:\\t\\t\\t*** Running the BayesianNetwork model - edges:\", edges)\n",
    "\n",
    "        # Construct the Bayesian Network model using the variables and edges to get the probabilities that\n",
    "        # each of the neighbours could be either a pit or Wumpus (depending on which method called it).\n",
    "\n",
    "        bayesian_network_model = BayesianNetwork(variables, edges)\n",
    "\n",
    "        # Create the tensor based on the neighbours and the current room.\n",
    "\n",
    "        # For example:\n",
    "        #       X = torch.tensor([[-1, -1, 0]])      # pit_1 ?, pit_2 ?, breeze is false \n",
    "        #       X = torch.tensor([[-1, -1, -1, 0]])  # pit_1 ?, pit_2 ?, pit_3 ?, breeze is false    \n",
    "        #       X = torch.tensor([[1, 1, 0, -1, 0]]) # pit_1 T, pit_2 T, pit_3 F, pit_4 ?, breeze is false\n",
    "\n",
    "        X = torch.tensor([room_and_breeze_list])\n",
    "\n",
    "        X_masked = torch.masked.MaskedTensor(X, mask=X >= 0)\n",
    "        if Global._debug: print (\"Status:\\t\\t\\t*** Running the BayesianNetwork model - Tensor mask:\", X_masked)\n",
    "\n",
    "        # Do the prediction.\n",
    "\n",
    "        bayesian_network_tensors = bayesian_network_model.predict_proba(X_masked)\n",
    "        if Global._display: print (\"Status:\\t\\t\\t*** Running the BayesianNetwork model - Tensors:\", bayesian_network_tensors)\n",
    "\n",
    "        # Extract the probabilities for each of the neighbours to allow the Agent to make the best decision based\n",
    "        # on probability reasoning.\n",
    "\n",
    "        neighbour_prob_dict = {}\n",
    "        tensor_idx = 0\n",
    "\n",
    "        # Iterate over the room's neighbours.\n",
    "\n",
    "        for breeze_room_neighbour in breeze_room_neighbours:\n",
    "            \n",
    "            # Extract the True and False values, put it into a dictionary and set it on the \n",
    "            # neighbour probability dictionary.\n",
    "\n",
    "            breeze_room_neighbour_tensor = bayesian_network_tensors[tensor_idx]\n",
    "            breeze_room_neighbour_tensor_probs_list = breeze_room_neighbour_tensor.tolist()\n",
    "\n",
    "            true_false_dict = {}\n",
    "            true_false_dict[\"False\"] = breeze_room_neighbour_tensor_probs_list[0][0]\n",
    "            true_false_dict[\"True\"]  = breeze_room_neighbour_tensor_probs_list[0][1]\n",
    "\n",
    "            neighbour_prob_dict[breeze_room_neighbour] = true_false_dict\n",
    "\n",
    "            # Go to the next Tensor.\n",
    "\n",
    "            tensor_idx = tensor_idx + 1\n",
    "\n",
    "        # Return the dictionary of neighbours and their probabilities.\n",
    "\n",
    "        return neighbour_prob_dict\n",
    "\n",
    "\n",
    "    # _create_cases_with_two_neighbours\n",
    "    #\n",
    "    # Courtesy of Larry Simon\n",
    "\n",
    "    def _create_cases_with_two_neighbours(self) -> []:\n",
    "\n",
    "        # Initialize the grid.\n",
    "\n",
    "        grid = []\n",
    "\n",
    "        # For two neighbours, the grid will include just layers.\n",
    "\n",
    "        # Iterate over the two T/F values.\n",
    "\n",
    "        for i in [False, True]:\n",
    "\n",
    "            # Layer level.\n",
    "\n",
    "            layer = []\n",
    "\n",
    "            # Iterate over the two T/F values.\n",
    "\n",
    "            for j in [False, True]:\n",
    "\n",
    "                # Case level.\n",
    "\n",
    "                case = i or j      \n",
    "\n",
    "                if case:\n",
    "                    p = 1.0\n",
    "                else:\n",
    "                    p = 0.0\n",
    "\n",
    "                # Append the case to the layer.\n",
    "\n",
    "                layer.append(PredicateC(p).toList())  # row\n",
    "\n",
    "            # Append the layer to the grid.\n",
    "\n",
    "            grid.append(layer)\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\t*** Cases grid with 2 neighbours:\", grid)\n",
    "\n",
    "        return grid\n",
    "\n",
    "\n",
    "    # _create_cases_with_three_neighbours\n",
    "    #\n",
    "    # Extending Larry Simon's method.\n",
    "\n",
    "    def _create_cases_with_three_neighbours(self) -> []:\n",
    "\n",
    "        # Initialize the grid.\n",
    "\n",
    "        grid = []\n",
    "\n",
    "        # For three neighbours, the grid will include a cube and layers.\n",
    "\n",
    "        # Iterate over the two T/F values.\n",
    "\n",
    "        for h in [False, True]:\n",
    "\n",
    "            # Cube level.\n",
    "\n",
    "            cube = []\n",
    "\n",
    "            # Iterate over the two T/F values.\n",
    "\n",
    "            for i in [False, True]:\n",
    "\n",
    "                # Layer level.\n",
    "\n",
    "                layer = []\n",
    "\n",
    "                # Iterate over the two T/F values.\n",
    "\n",
    "                for j in [False, True]:\n",
    "\n",
    "                    # Case level.\n",
    "\n",
    "                    case = i or j      \n",
    "\n",
    "                    if case:\n",
    "                        p = 1.0\n",
    "                    else:\n",
    "                        p = 0.0\n",
    "\n",
    "                    # Append the case to the layer.\n",
    "\n",
    "                    layer.append(PredicateC(p).toList())  # row\n",
    "\n",
    "                # Append the layer to the cube.\n",
    "\n",
    "                cube.append(layer)\n",
    "                \n",
    "            # Append the cube to the grid.\n",
    "\n",
    "            grid.append(cube)\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\t*** Cases grid with 3 neighbours:\", grid)\n",
    "\n",
    "        return grid\n",
    "\n",
    "\n",
    "    # _create_cases_with_four_neighbours\n",
    "    #\n",
    "    # Extending Larry Simon's method.\n",
    "\n",
    "    def _create_cases_with_four_neighbours(self) -> []:\n",
    "\n",
    "        # Initialize the grid.\n",
    "\n",
    "        grid = []\n",
    "\n",
    "        # For four neighbours, the grid will include a structure, cube and layers.\n",
    "\n",
    "        # Iterate over the two T/F values.\n",
    "\n",
    "        for g in [False, True]:\n",
    "\n",
    "            # Structure level.\n",
    "\n",
    "            structure = [] \n",
    "\n",
    "            # Iterate over the two T/F values.\n",
    "\n",
    "            for h in [False, True]:\n",
    "\n",
    "                # Cube level.\n",
    "\n",
    "                cube = []\n",
    "\n",
    "                # Iterate over the two T/F values.\n",
    "\n",
    "                for i in [False, True]:\n",
    "\n",
    "                    # Layer level.\n",
    "\n",
    "                    layer = []\n",
    "\n",
    "                    # Iterate over the two T/F values.\n",
    "\n",
    "                    for j in [False, True]:\n",
    "                        \n",
    "                        # Case level.\n",
    "\n",
    "                        case = i or j     \n",
    "\n",
    "                        if case:\n",
    "                            p = 1.0\n",
    "                        else:\n",
    "                            p = 0.0\n",
    "\n",
    "                        # Append the case to the layer.\n",
    "\n",
    "                        layer.append(PredicateC(p).toList())  # row\n",
    "\n",
    "                    # Append the layer to the cube.\n",
    "\n",
    "                    cube.append(layer)\n",
    "\n",
    "                # Append the cube to the structure.\n",
    "                \n",
    "                structure.append(cube)\n",
    "\n",
    "            # Append the structure to the grid.\n",
    "\n",
    "            grid.append(structure)\n",
    "\n",
    "        if Global._display: print (\"Status:\\t\\t\\t*** Cases grid with 4 neighbours:\", grid)\n",
    "\n",
    "        return grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d198f4-04ca-418e-aabf-3a01525f5f35",
   "metadata": {},
   "source": [
    "Define the Abstract Character State, the abstract super class for the Environment to manage the Agent and Wumpus characters' states ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db226a8f-b6b0-403b-8f16-edb9444aa52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CharacterStateA.py\n",
    "\n",
    "class CharacterStateA:\n",
    "\n",
    "    # Constructor.\n",
    "\n",
    "    def __init__(self, location):\n",
    "\n",
    "        # General.\n",
    "\n",
    "        self.location = location\n",
    "        self.isAlive = True\n",
    "\n",
    "\n",
    "    # Getters and Setters.\n",
    "\n",
    "    def get_location(self) -> ():\n",
    "        return self.location\n",
    "\n",
    "    def set_location(self, location):\n",
    "        self.location = location\n",
    "\n",
    "    def get_isAlive(self) -> bool:\n",
    "        return self.isAlive\n",
    "\n",
    "    def set_isAlive(self, isAlive):\n",
    "        self.isAlive = isAlive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4649758-fcc2-430e-aecc-9507a93952cc",
   "metadata": {},
   "source": [
    "Define the Agent State class, the concrete sub-class of the Abstract Character State so the Environment can manage the state of the Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84fcd54c-4c66-485d-ba67-27f17ce6a659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AgentStateC.py\n",
    "\n",
    "\n",
    "class AgentStateC(CharacterStateA):\n",
    "\n",
    "\n",
    "    # Default constructor.\n",
    "\n",
    "    def __init__(self, location):\n",
    "\n",
    "        # Call the super class to set the location.\n",
    "\n",
    "        super().__init__(location)\n",
    "\n",
    "        # Define attributes specific to AgentStateC.\n",
    "\n",
    "        self.orientation = Global._east\n",
    "        self.facing = Global._right\n",
    "\n",
    "        self.hasGold = False\n",
    "        self.hasArrow = True\n",
    "        self.hasClimbedOut = False\n",
    "\n",
    "        # Initialize the score to 0.\n",
    "\n",
    "        self.score = 0\n",
    "\n",
    "\n",
    "    # Define Getters and Setters.\n",
    "\n",
    "    def get_orientation(self) -> str:\n",
    "        return self.orientation\n",
    "\n",
    "    def set_orientation(self, orientation):\n",
    "        self.orientation = orientation\n",
    "\n",
    "    def get_facing(self) -> str:\n",
    "        return self.facing\n",
    "\n",
    "    def set_facing(self, facing):\n",
    "        self.facing = facing\n",
    "\n",
    "    def get_hasGold(self) -> bool:\n",
    "        return self.hasGold\n",
    "\n",
    "    def set_hasGold(self, hasGold):\n",
    "        self.hasGold = hasGold\n",
    "\n",
    "    def get_hasArrow(self) -> bool:\n",
    "        return self.hasArrow\n",
    "\n",
    "    def set_hasArrow(self, hasArrow):\n",
    "        self.hasArrow = hasArrow\n",
    "    \n",
    "    def get_hasClimbedOut(self) -> bool:\n",
    "        return self.hasClimbedOut\n",
    "\n",
    "    def set_hasClimbedOut(self, hasClimbedOut):\n",
    "        self.hasClimbedOut = hasClimbedOut\n",
    "\n",
    "    def get_score(self) -> int:\n",
    "        return self.score\n",
    "\n",
    "    def set_score(self, score):\n",
    "        self.score = score\n",
    "\n",
    "    def update_score(self, score_value):\n",
    "        self.score = self.score + score_value\n",
    "\n",
    "\n",
    "    # forward\n",
    "\n",
    "    def forward(self) -> ():\n",
    "\n",
    "        # Only advance the Agent if within the cave boundaries.\n",
    "\n",
    "        current_loc_col = self.location[0]\n",
    "        current_loc_row = self.location[1]\n",
    "\n",
    "        if (self.orientation == Global._south):\n",
    "            current_loc_row = current_loc_row - 1\n",
    "        elif (self.orientation == Global._north):\n",
    "            current_loc_row = current_loc_row + 1\n",
    "        elif (self.orientation == Global._east):\n",
    "            current_loc_col = current_loc_col + 1\n",
    "        elif (self.orientation == Global._west):\n",
    "            current_loc_col = current_loc_col - 1\n",
    "\n",
    "        if Global._display: print (\"Action Result:\\t\\tAgent is looking to move\", self.orientation, \"to\", (current_loc_col, current_loc_row))\n",
    "\n",
    "        return (current_loc_col, current_loc_row)\n",
    "\n",
    "\n",
    "    # turnLeft\n",
    "\n",
    "    def turnLeft(self):\n",
    "\n",
    "        # Update the Agent's orientation based on its current orientation.\n",
    "\n",
    "        orientation_index = Global._orientation_array.index(self.orientation)\n",
    "        self.orientation = Global._orientation_array[orientation_index-1]\n",
    "\n",
    "        if Global._display: print (\"Action Result:\\t\\tAgent has turned left and is now facing\", self.orientation)\n",
    "        \n",
    "    \n",
    "    # turnRight\n",
    "\n",
    "    def turnRight(self):\n",
    "\n",
    "        # Update the Agent's orientation based on its current orientation.\n",
    "\n",
    "        orientation_index = Global._orientation_array.index(self.orientation)\n",
    "        right_index = orientation_index + 1\n",
    "\n",
    "        # Unlike the turnRight method, an index larger than the array is an out\n",
    "        # of bounds error.  Check for this condition (len will be the index of the\n",
    "        # out of bounds as array starts at 0).\n",
    "\n",
    "        if (right_index == len(Global._orientation_array)):\n",
    "            right_index = 0\n",
    "\n",
    "        self.orientation = Global._orientation_array[right_index]\n",
    "\n",
    "        if Global._display: print (\"Action Result:\\t\\tAgent has turned right and is now facing\", self.orientation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f726f-e842-4ac5-8960-9dd1cf0ff38a",
   "metadata": {},
   "source": [
    "Define the Wumpus State class, the concrete sub-class of the Abstract Character State so the Environment can manage the state of the Wumpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8740420-e228-4b2c-a51e-cffff8b9087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WumpusStateC.py\n",
    "\n",
    "class WumpusStateC(CharacterStateA):\n",
    "\n",
    "    # Constructor.\n",
    "\n",
    "    def __init__(self, location):\n",
    "\n",
    "        # Call the super class to set the location.\n",
    "\n",
    "        super().__init__(location)\n",
    "\n",
    "        # No other attributes required for WumpusState other than \n",
    "        # what is provided in the super class (location, isAlive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76416c-df12-4b12-bdb8-f4ae90fcc800",
   "metadata": {},
   "source": [
    "Define the Environment class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "072e62c9-10e5-4b2e-a510-7764d642d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries.\n",
    "\n",
    "import random\n",
    "\n",
    "# class: EnvironmentC\n",
    "\n",
    "class EnvironmentC:\n",
    "    \n",
    "    # Constructor.\n",
    "    \n",
    "    def __init__(self, width=4, height=4, allowClimbWithoutGold=True, pitProb=0.2):\n",
    "\n",
    "        self.active_episode = True\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.allowClimbWithoutGold = allowClimbWithoutGold\n",
    "        self.pitProb = pitProb\n",
    "\n",
    "        # Create an array to keep track of which rooms are not available.\n",
    "\n",
    "        unavailable_rooms_array = []\n",
    "\n",
    "        # Initialize the Agent and add its location to the unavailable rooms list.\n",
    "    \n",
    "        self.agent_location = (1, 1)\n",
    "        self.agentState = AgentStateC(self.agent_location)\n",
    "        unavailable_rooms_array.append(self.agent_location)\n",
    "\n",
    "        # Initialize the location of the Wumpus and add its location to the unavailable rooms list (maybe future).\n",
    "\n",
    "        self.wumpus_location = self.__get_random_coordinate(unavailable_rooms_array)\n",
    "        self.wumpusState = WumpusStateC(self.wumpus_location)\n",
    "        # unavailable_rooms_array.append(self.wumpus_location)\n",
    "\n",
    "        # Initialize the location of the Gold and add its location to the unavailable rooms list (maybe future).\n",
    "\n",
    "        self.gold_location = self.__get_random_coordinate(unavailable_rooms_array)\n",
    "        # unavailable_rooms_array.append(self.gold_location)\n",
    "\n",
    "        # Initialize the location of the pits based on the unavailable list (currently, just the Agent).\n",
    "\n",
    "        self.pit_locations = self.__determine_pit_locations(unavailable_rooms_array)\n",
    "\n",
    "\n",
    "    # is_active_episode\n",
    "\n",
    "    def is_active_episode(self) -> bool:\n",
    "\n",
    "        # An episode is still active if the Agent is still alive and has not yet\n",
    "        # climbed out of the cave.\n",
    "\n",
    "        if ((self.agentState.get_isAlive()) and (self.agentState.get_hasClimbedOut() == False)):\n",
    "            return True\n",
    "\n",
    "        # Inactive episode.\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "    # get_Agent_Score\n",
    "\n",
    "    def get_Agent_Score(self) -> int:\n",
    "\n",
    "        return self.agentState.get_score()\n",
    "\n",
    "\n",
    "    # display_initial_episode\n",
    "\n",
    "    def display_initial_episode(self):\n",
    "\n",
    "        print (\"The Episode:\")\n",
    "        print (\"------------\")\n",
    "        print (\"The Agent is at: \\t\", self.agent_location)\n",
    "        print (\"The Wumpus is at: \\t\", self.wumpus_location)\n",
    "        print (\"The Gold is at: \\t\", self.gold_location)\n",
    "        print (\"The Pit(s) are at: \\t\", self.pit_locations)\n",
    "        print (\"The Agent is facing: \\t\", self.agentState.get_orientation())\n",
    "        print (\"------------\")\n",
    "\n",
    "        # Display the initial episode board.\n",
    "\n",
    "        self.display_board()\n",
    "\n",
    "\n",
    "    # display_board\n",
    "\n",
    "    def display_board(self):\n",
    "        \n",
    "        print (\"The agent score is:\\t\", self.agentState.get_score())\n",
    "\n",
    "        print (\"\\n\\t     \", end='')\n",
    "\n",
    "        # Draw the x grid coordinates.\n",
    "\n",
    "        for x in range(1, self.width+1):\n",
    "            print (' ', x, '   ', end='')\n",
    "\n",
    "        print (\"\\n\")\n",
    "\n",
    "        # Get the orientation of the Agent.\n",
    "\n",
    "        agent_orientation = self.agentState.get_orientation()\n",
    "\n",
    "        # Draw the y grid starting from height.\n",
    "\n",
    "        for y in range(self.height, 0, -1):\n",
    "            \n",
    "            # Draw the northern orientation layer.\n",
    "            \n",
    "            print (\"\\t     \", end='')\n",
    "\n",
    "            for z in range(1, self.width+1):\n",
    "\n",
    "                # Determine if this is the area the Agent is facing north.\n",
    "\n",
    "                if ((z, y) == self.agent_location) and (agent_orientation == Global._north):\n",
    "                    print ('  ^    ', end='')\n",
    "                else:\n",
    "                    print ('       ', end='')\n",
    "\n",
    "            # Tab over for more readability and output the y grid coordinate.\n",
    "\n",
    "            print (\"\\n\\t\", y, \"  \", end='')\n",
    "\n",
    "            # Draw the x grid starting from 1.\n",
    "\n",
    "            for x in range(1, self.width+1):\n",
    "\n",
    "                if ((x, y) == self.agent_location) and (agent_orientation == Global._west):\n",
    "\n",
    "                    # Display the Agent facing west.\n",
    "\n",
    "                    print ('< A  ', ' ', end='')\n",
    "\n",
    "                elif ((x, y) == self.agent_location) and (agent_orientation == Global._east):\n",
    "\n",
    "                    # Display the Agent facing east.\n",
    "\n",
    "                    print ('  A >', ' ', end='')\n",
    "\n",
    "                elif ((x, y) == self.agent_location):\n",
    "\n",
    "                    # Display the Agent (facing either north or south).\n",
    "\n",
    "                    print ('  A  ', ' ', end='')\n",
    "\n",
    "                elif ((x, y) == self.wumpus_location):\n",
    "\n",
    "                    # Determine if the Wumpus is dead or alive.\n",
    "\n",
    "                    if (self.wumpusState.get_isAlive()):\n",
    "                        print ('  W  ', ' ', end='')\n",
    "                    else:\n",
    "                        print ('  w  ', ' ', end='')\n",
    "\n",
    "                elif ((x, y) == self.gold_location) and (self.agentState.get_hasGold() == False):\n",
    "\n",
    "                    # Determine if the Gold has already been grabbed.\n",
    "\n",
    "                    print ('  G  ', ' ', end='')\n",
    "\n",
    "                elif ((x, y) in self.pit_locations):\n",
    "                    print ('  P  ', ' ', end='')\n",
    "\n",
    "                else:\n",
    "                    print ('     ', ' ', end='')\n",
    "\n",
    "            # Draw the southern orientation layer.\n",
    "             \n",
    "            print (\"\\n\\t     \", end='')\n",
    "          \n",
    "            for z in range(1, self.width+1):\n",
    "\n",
    "                # Determine if this is the area the Agent is facing south.\n",
    "\n",
    "                if ((z, y) == self.agent_location) and (agent_orientation == Global._south):\n",
    "                    print ('  V    ', end='')\n",
    "                else:\n",
    "                    print ('       ', end='')\n",
    "\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "    # get_percepts\n",
    "\n",
    "    def get_percepts(self) -> PerceptsC:\n",
    "\n",
    "        agent_percepts = PerceptsC()\n",
    "\n",
    "        # Pits.  If the Agent is adjacent to a pit send a breeze percept.\n",
    "\n",
    "        for loc in self.pit_locations:\n",
    "\n",
    "            pit_adjacent_rooms = []\n",
    "\n",
    "            curr_loc_col = loc[0]\n",
    "            curr_loc_row = loc[1]\n",
    "\n",
    "            pit_adjacent_rooms.append((curr_loc_col, curr_loc_row+1)) # north\n",
    "            pit_adjacent_rooms.append((curr_loc_col, curr_loc_row-1)) # south\n",
    "            pit_adjacent_rooms.append((curr_loc_col+1, curr_loc_row)) # east\n",
    "            pit_adjacent_rooms.append((curr_loc_col-1, curr_loc_row)) # west\n",
    "\n",
    "            if self.agent_location in pit_adjacent_rooms:\n",
    "                agent_percepts.set_breeze(True)\n",
    "                break\n",
    "\n",
    "\n",
    "        # Wampus.  If the Agent is adjacent to the Wumpus or is on top of a dead\n",
    "        # Wampus, send a stench percept.\n",
    "\n",
    "        wampus_adjacent_rooms = []\n",
    "\n",
    "        wampus_col = self.wumpus_location[0]\n",
    "        wampus_row = self.wumpus_location[1]\n",
    "\n",
    "        wampus_adjacent_rooms.append((wampus_col, wampus_row+1)) # north\n",
    "        wampus_adjacent_rooms.append((wampus_col, wampus_row-1)) # south\n",
    "        wampus_adjacent_rooms.append((wampus_col+1, wampus_row)) # east\n",
    "        wampus_adjacent_rooms.append((wampus_col-1, wampus_row)) # west\n",
    "\n",
    "        if self.agent_location in wampus_adjacent_rooms:\n",
    "            agent_percepts.set_stench(True)\n",
    "\n",
    "        # Gold.  If the Agent is in the same room as the gold\n",
    "        # send a glitter percept.\n",
    "\n",
    "        if (self.agent_location == self.gold_location):\n",
    "            agent_percepts.set_glitter(True)\n",
    "\n",
    "        return agent_percepts\n",
    "\n",
    "\n",
    "    # take_action\n",
    "\n",
    "    def take_action(self, action) -> PerceptsC:\n",
    "\n",
    "        my_actionPercepts = PerceptsC()\n",
    "\n",
    "        # Time to take action.  Regardless of the outcome, update \n",
    "        # the score by -1.\n",
    "\n",
    "        self.agentState.update_score(-1)\n",
    "\n",
    "        if Global._display: print (\"Action Result:\\t\\tAgent is currently at\", self.agent_location, \"facing\", self.agentState.get_orientation())\n",
    "\n",
    "        if (action == Global._forward_action):  \n",
    "            my_actionPercepts = self.__forward_action()\n",
    "\n",
    "        elif (action == Global._turnLeft_action):\n",
    "            self.__turnLeft_action()\n",
    "\n",
    "        elif (action == Global._turnRight_action):\n",
    "            self.__turnRight_action()\n",
    "\n",
    "        elif (action == Global._shoot_action):\n",
    "            my_actionPercepts = self.__shoot_action()\n",
    "\n",
    "        elif (action == Global._grab_action):\n",
    "            self.__grab_action()\n",
    "\n",
    "        elif (action == Global._climb_action):\n",
    "            self.__climb_action()\n",
    "\n",
    "        else:\n",
    "            if Global._display: print (\"Invalid action\", action)\n",
    "\n",
    "        return my_actionPercepts\n",
    "\n",
    "\n",
    "    # Private methods\n",
    "\n",
    "\n",
    "    # __get_random_coordinate\n",
    "\n",
    "    def __get_random_coordinate(self, unavailable_rooms_array) -> tuple([int, int]):\n",
    "\n",
    "        # Get a random coordinate.  Keep trying until the random coordinate\n",
    "        # is available.\n",
    "\n",
    "        attempts = 0\n",
    "\n",
    "        grid_size = self.width * self.height\n",
    "\n",
    "        while (attempts != grid_size):\n",
    "            random_row = random.randint(1, self.height)\n",
    "            random_col = random.randint(1, self.width)\n",
    "\n",
    "            if ((random_col, random_row) not in unavailable_rooms_array):\n",
    "                break\n",
    "\n",
    "            attempts = attempts + 1\n",
    "\n",
    "        # Check to see if all points on the board are unavailable.\n",
    "\n",
    "        if (attempts == grid_size):\n",
    "            random_col, random_row = 0\n",
    "\n",
    "        return (random_col, random_row)\n",
    "\n",
    "\n",
    "    # __determine_pit_locations\n",
    "\n",
    "    def __determine_pit_locations(self, unavailable_rooms_array) -> list [(int, int)]:\n",
    "\n",
    "        pit_list = []\n",
    "        pit_or_nopit = [ 'P', '-' ]\n",
    "        pit_probabilities = [self.pitProb, (1 - self.pitProb)]\n",
    "\n",
    "        for i in range(1, self.height+1):\n",
    "\n",
    "            for j in range(1, self.width+1):\n",
    "\n",
    "                if ((i, j) not in unavailable_rooms_array):\n",
    "\n",
    "                    pit = random.choices(pit_or_nopit, weights=pit_probabilities, k=1)[0]\n",
    "\n",
    "                    if (pit == 'P'):\n",
    "                        pit_list.append((i, j))\n",
    "\n",
    "        return pit_list\n",
    "\n",
    "\n",
    "    # __forward_action\n",
    "\n",
    "    def __forward_action(self) -> PerceptsC:\n",
    "\n",
    "        my_actionPercepts = PerceptsC()\n",
    "\n",
    "        # Get the candidate move location from the Agent moving forward.\n",
    "        # The move location is only a 'candidate' until the Environment can\n",
    "        # ascertain that it is a valid grid location.\n",
    "\n",
    "        candidate_move_loc = self.agentState.forward()\n",
    "\n",
    "        candidate_loc_col = candidate_move_loc[0]\n",
    "        candidate_loc_row = candidate_move_loc[1]\n",
    "        \n",
    "        if ((candidate_loc_col < 1) or (candidate_loc_col > self.width) or \n",
    "            (candidate_loc_row < 1) or (candidate_loc_row > self.height)):\n",
    "\n",
    "            # Invalid forward move.  Set the Bump percept.\n",
    "\n",
    "            if Global._display: print(\"Action Result:\\t\\tInvalid forward move (out of bounds).  Agent remains at\",self.agent_location)\n",
    "            my_actionPercepts.set_bump(True)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Valid forward move.\n",
    "        \n",
    "            self.agentState.set_location(candidate_move_loc)\n",
    "            self.agent_location = candidate_move_loc\n",
    "            my_actionPercepts.set_move(candidate_move_loc)\n",
    "            my_actionPercepts.set_direction(self.agentState.get_orientation())\n",
    "\n",
    "            if Global._display: print(\"Action Result:\\t\\tValid forward move.  Agent is now at\", self.agent_location)\n",
    "\n",
    "            self.__determine_forward_fate()\n",
    "\n",
    "        return my_actionPercepts\n",
    "\n",
    "\n",
    "    # __determine_forward_fate\n",
    "\n",
    "    def __determine_forward_fate(self):\n",
    "\n",
    "        # Determine if the move forward action by the Agent has resulted in running into a\n",
    "        # pit or an alive Wumpus.\n",
    "\n",
    "        if (self.agent_location in self.pit_locations):\n",
    "\n",
    "            if Global._display: print (\"Action Result:\\t\\t*** Agent has fallen into a pit ***\")\n",
    "            self.agentState.set_isAlive(False)\n",
    "\n",
    "            # The Agent has fallen into a pit.  Update the score -1000.\n",
    "\n",
    "            self.agentState.update_score(-1000)\n",
    "\n",
    "\n",
    "        elif ((self.agent_location == self.wumpus_location) and\n",
    "              (self.wumpusState.get_isAlive())):\n",
    "\n",
    "            if Global._display: print (\"Action Result:\\t\\t*** Agent has been eaten by the Wumpus ***\")\n",
    "            self.agentState.set_isAlive(False)\n",
    "\n",
    "            # The Agent has been eaten by the Wumpus.  Update the score -1000.\n",
    "\n",
    "            self.agentState.update_score(-1000)\n",
    "        else:\n",
    "\n",
    "            # No fate on the Agent moving forward.\n",
    "            # Agent can continue.\n",
    "\n",
    "            pass\n",
    "\n",
    "\n",
    "    # __shoot_action\n",
    "\n",
    "    def __shoot_action(self) -> PerceptsC:\n",
    "\n",
    "        my_actionPercepts = PerceptsC()\n",
    "\n",
    "        if Global._display: print (\"Action Result:\\t\\tDoes the Agent have the arrow?\", self.agentState.get_hasArrow())\n",
    "\n",
    "        # If the Agent has the arrow then it can be fired.\n",
    "\n",
    "        if (self.agentState.get_hasArrow()):\n",
    "\n",
    "            # The arrow has been shot.  Update the score -10.\n",
    "            if Global._display: print (\"Action Result:\\t\\tThe Agent has shot the arrow\")\n",
    "\n",
    "            self.agentState.update_score(-10)\n",
    "\n",
    "            orientation = self.agentState.get_orientation()\n",
    "            current_loc = self.agentState.get_location()\n",
    "            current_loc_col = current_loc[0]\n",
    "            current_loc_row = current_loc[1]\n",
    "\n",
    "            arrow_flight_path = []\n",
    "\n",
    "            # Determine the arrow flight path through the cave based on the\n",
    "            # direction the Agent is facing.\n",
    "\n",
    "            if (orientation == Global._south):\n",
    "                # South\n",
    "\n",
    "                for i in range(current_loc_row-1, 0, -1):\n",
    "                    arrow_flight_path.append((current_loc_col, i))\n",
    "\n",
    "            elif (orientation == Global._north):\n",
    "                # North\n",
    "                \n",
    "                for i in range(current_loc_row+1, 4+1):\n",
    "                    arrow_flight_path.append((current_loc_col, i))\n",
    "            elif (orientation == Global._east):\n",
    "                # East\n",
    "\n",
    "                for i in range(current_loc_col+1, 4+1):\n",
    "                    arrow_flight_path.append((i, current_loc_row))\n",
    "            elif (orientation == Global._west):\n",
    "                # West\n",
    "\n",
    "                for i in range(current_loc_col-1, 0, -1):\n",
    "                    arrow_flight_path.append((i, current_loc_row))\n",
    "                    \n",
    "            # Iterate over the rooms that are in the shooting path.\n",
    "\n",
    "            for room_location in arrow_flight_path:\n",
    "\n",
    "                if Global._display: print (\"Action Result:\\t\\tArrow is travelling through room\", room_location, '.. ', end='')\n",
    "\n",
    "                # Is the Wumpus in this room?\n",
    "\n",
    "                if (room_location == self.wumpus_location):\n",
    "                   # Yes.\n",
    "\n",
    "                    if Global._display: print (\"*** The Wumpus has been killed ***\")\n",
    "\n",
    "                    # Update the precepts and set the Wumpus alive status to False.\n",
    "\n",
    "                    my_actionPercepts.set_scream(True)\n",
    "                    self.wumpusState.set_isAlive(False)\n",
    "                    break;\n",
    "                else:\n",
    "                    # No.\n",
    "\n",
    "                    if Global._display: print (\"The Wumpus is not in room\", room_location)\n",
    "\n",
    "            # Remove the arrow from the Agent state.\n",
    "\n",
    "            self.agentState.set_hasArrow(False)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # The arrow has already been shot.\n",
    "            if Global._display: print (\"Action Result:\\t\\tThe Agent has already shot the arrow\")\n",
    "\n",
    "\n",
    "        # Return the new set of percepts that occurred post-action firing.\n",
    "\n",
    "        return my_actionPercepts\n",
    "\n",
    "\n",
    "    # __grab_action\n",
    "\n",
    "    def __grab_action(self):\n",
    "\n",
    "        # Determine if the Gold is in the same room as the Agent.\n",
    "\n",
    "        if (self.agent_location == self.gold_location):\n",
    "            if Global._display: print(\"Action Result:\\t\\t*** The Agent has grabbed the gold ***\")\n",
    "            self.agentState.set_hasGold(True)\n",
    "\n",
    "        else:\n",
    "            if Global._display: print(\"Action Result:\\t\\tThere is no gold in room\", self.agent_location)\n",
    "\n",
    "\n",
    "    # __climb_action\n",
    "\n",
    "    def __climb_action(self):\n",
    "\n",
    "        # The Agent can only climb out from the original room.\n",
    "\n",
    "        if (self.agent_location == Global._start_room):\n",
    "\n",
    "            # Determine if the Agent has the gold.\n",
    "\n",
    "            if (self.agentState.get_hasGold()):\n",
    "                \n",
    "                # The gold has been grabbed and climbing out.  Update the score +1000.\n",
    "\n",
    "                self.agentState.update_score(1000)\n",
    "\n",
    "                if Global._display: print (\"Action Result:\\t\\t*** The Agent is climbing out with the gold :-) ***\")\n",
    "                self.agentState.set_hasClimbedOut(True)\n",
    "\n",
    "            else:\n",
    "                # The Agent can only climb out without the gold if the\n",
    "                # episode permits its.\n",
    "\n",
    "                if (self.allowClimbWithoutGold):\n",
    "                    if Global._display: print (\"Action Result:\\t\\t*** The Agent is climbing out without the gold :-( ***\")\n",
    "                    self.agentState.set_hasClimbedOut(True)\n",
    "\n",
    "                else:\n",
    "                    if Global._display: print (\"Action Result:\\t\\tThe Agent cannot climb out without the gold\")\n",
    "\n",
    "        else:\n",
    "            # The Agent is not in the original room.\n",
    "\n",
    "            if Global._display: print (\"Action Result:\\t\\tThe Agent cannot climb out as they are not in the original room\", Global._start_room)\n",
    "\n",
    "\n",
    "    # __turnRight_action\n",
    "\n",
    "    def __turnRight_action(self):\n",
    "\n",
    "        # Agent turns right.\n",
    "\n",
    "        self.agentState.turnRight()\n",
    "\n",
    "\n",
    "    # __turnLeft_action\n",
    "\n",
    "    def __turnLeft_action(self):\n",
    "\n",
    "        # Agent turns left.\n",
    "\n",
    "        self.agentState.turnLeft()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323ac3fd-1211-427f-bf23-50596d09ba7b",
   "metadata": {},
   "source": [
    "Define the Episode Controller which will create the Agent and the Environment and then run the episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "081b5eac-204c-4dcd-8312-287236da496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EpisodeControllerC.py\n",
    "\n",
    "\n",
    "class EpisodeControllerC():\n",
    "    \n",
    "    # Constructor.\n",
    "\n",
    "    def __init__(self, agent, environment):\n",
    "        \n",
    "        # The Episode Controller requires an Agent and an Environment.\n",
    "\n",
    "        self.agent = agent\n",
    "        self.environment = environment\n",
    "\n",
    "\n",
    "    # playEpisode\n",
    "\n",
    "    def playEpisode(self) -> int:\n",
    "\n",
    "        # Display the initial board.\n",
    "\n",
    "        if Global._display: self.environment.display_initial_episode()\n",
    "\n",
    "        # Execute the episode until it is no longer active.\n",
    "\n",
    "        agent_move = 0\n",
    "        \n",
    "        while (self.environment.is_active_episode()):\n",
    "\n",
    "            # Increase the agent_move to track the number of movements in the episode.\n",
    "            \n",
    "            agent_move = agent_move + 1\n",
    "            \n",
    "            if Global._display: print (\">>----- Agent Move\", agent_move, \"----->>\")\n",
    "            \n",
    "            # Get the pre-action Percepts to notify the Agent.\n",
    "\n",
    "            pre_action_percepts = self.environment.get_percepts()\n",
    "\n",
    "            # Notify the Agent of the pre-action percepts.\n",
    "\n",
    "            self.agent.percept(pre_action_percepts)\n",
    "\n",
    "            # The Agent will now select its next action.\n",
    "\n",
    "            action = self.agent.action()\n",
    "\n",
    "            # Take the action selected by the Agent in the Environment.\n",
    "\n",
    "            post_action_percepts = self.environment.take_action(action)\n",
    "           \n",
    "            # Determine if this is still an active episode after the action\n",
    "            # has been taken (e.g., the Agent hasn't fallen into a pit or\n",
    "            # has been eaten by the Wumpus).\n",
    "\n",
    "            if (self.environment.is_active_episode()):\n",
    "\n",
    "                # Notify the Agent of the post-action percepts.\n",
    "\n",
    "                self.agent.percept(post_action_percepts)\n",
    "\n",
    "            # Display the game board after each action.\n",
    "\n",
    "            if Global._display: self.environment.display_board()\n",
    "\n",
    "\n",
    "        # Return the final score for the Agent.\n",
    "\n",
    "        return self.environment.get_Agent_Score(), agent_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd7a528-0bc5-4ca7-b069-728e00935a4d",
   "metadata": {},
   "source": [
    "Define the Wumpus Driver that is the entry point for the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ef9d612-1ceb-484c-b942-a7b1c2f01ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WumpusDriver.py\n",
    "\n",
    "# Import libraries.\n",
    "\n",
    "import warnings\n",
    "\n",
    "# main\n",
    "\n",
    "def main(agent_arg, episodes):\n",
    "\n",
    "    # Filter out all warnings.\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Set local variables.\n",
    "\n",
    "    number_of_episodes = episodes\n",
    "    episode_wins = 0\n",
    "    episode_scares = 0\n",
    "    episode_total_score = 0\n",
    "\n",
    "    print (\"Ready Player 1\")\n",
    "    print (\"--------------\")\n",
    "    print (\"Starting the game... there are\", number_of_episodes, \"episodes to play.\")\n",
    "\n",
    "    for i in range(number_of_episodes):\n",
    "\n",
    "        # Initialize the Agent.\n",
    "\n",
    "        # For Project 1, use the Naive Agent (does not store location, all actions are random)\n",
    "        # For Project 2, use the Move Planning Agent (stores location, move / turns are random, exit plan on gold)\n",
    "        # For Project 3, use the Probability Agent (stores location, moves based on probability, exit plan on gold or danger)\n",
    "\n",
    "        myAgent = None\n",
    "\n",
    "        # Determine the Agent to use.\n",
    "\n",
    "        if (agent_arg == \"Naive\"):\n",
    "\n",
    "            myAgent = NaiveAgentC()\n",
    "\n",
    "        elif (agent_arg == \"MovePlanning\"):\n",
    "\n",
    "            myAgent = MovePlanningAgentC(Global._start_room)\n",
    "        \n",
    "        elif (agent_arg == \"Prob\"):\n",
    "\n",
    "            myAgent = ProbAgentC(Global._start_room)\n",
    "\n",
    "        else:\n",
    "            # Default to the Naive Agent.\n",
    "\n",
    "            myAgent = NaiveAgentC()\n",
    "\n",
    "        # Initialize the environment.\n",
    "\n",
    "        myEnvironment = EnvironmentC()\n",
    "\n",
    "        # Initialize the game controller  and play the episode.\n",
    "\n",
    "        episodeController = EpisodeControllerC(myAgent, myEnvironment)\n",
    "        episodeScore, episodeMoves = episodeController.playEpisode()\n",
    "\n",
    "        # Print the final score for the Agent.\n",
    "\n",
    "        if Global._display: print (\"Episode Complete: the Agent's final score is:\", episodeScore, \"in\", episodeMoves, \"moves.\")\n",
    "\n",
    "        # Capture the wins.\n",
    "\n",
    "        if (episodeScore > 0):\n",
    "            episode_wins = episode_wins + 1\n",
    "\n",
    "        # Capture the times the Agent was too scared to continue.\n",
    "\n",
    "        if ((episodeScore < 0) and (episodeScore > -10)):\n",
    "            episode_scares = episode_scares + 1\n",
    "\n",
    "        episode_total_score = episode_total_score + episodeScore\n",
    "        if Global._display: print (\"episode_total_score:\", episode_total_score)\n",
    "\n",
    "        # Print out a status message every 100 episodes.\n",
    "\n",
    "        if ((i != 0) and ((i % 100) == 0)):\n",
    "            print (\"Completed\", i, \"episodes...\")\n",
    "\n",
    "\n",
    "    print (\"\\nStats:\")\n",
    "    print (\"------\")\n",
    "    print (\"Number of episodes:\", number_of_episodes)\n",
    "    print (\"Number of episode wins:\", episode_wins)\n",
    "    win_format = f\"% of wins: {(episode_wins / number_of_episodes) * 100:.2f}\"\n",
    "    print (win_format)\n",
    "    print (\"Number of times Agent was too scared or climbed out quickly:\", episode_scares)\n",
    "    scare_format = f\"% times Agent was too scared or climbed out quickly: {(episode_scares / number_of_episodes) * 100:.2f}\"\n",
    "    print (scare_format)\n",
    "    print (\"Average score:\", (episode_total_score / number_of_episodes))\n",
    "    print (\"\\nNote: for the Naive Agent, instead of being scared with reason, it is just simply climbing out\")\n",
    "    print (\"        for the Move Planning Agent, it cannot climb out without having the gold\")\n",
    "    print (\"        for the Probability Agent, it can climb out without having the gold if the next move is too dangerous for it\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34867592-cda5-4776-b8c9-1c9803fe2563",
   "metadata": {},
   "source": [
    "## <font color=\"Blue\">Agent Episodes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df22eb-67c7-4e16-860d-bc8d9890eef3",
   "metadata": {},
   "source": [
    "### <font color=\"Green\">Naive Agent</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9c183d1-bb57-4be0-8b5b-d483e5b14b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready Player 1\n",
      "--------------\n",
      "Starting the game... there are 1000 episodes to play.\n",
      "Completed 100 episodes...\n",
      "Completed 200 episodes...\n",
      "Completed 300 episodes...\n",
      "Completed 400 episodes...\n",
      "Completed 500 episodes...\n",
      "Completed 600 episodes...\n",
      "Completed 700 episodes...\n",
      "Completed 800 episodes...\n",
      "Completed 900 episodes...\n",
      "\n",
      "Stats:\n",
      "------\n",
      "Number of episodes: 1000\n",
      "Number of episode wins: 14\n",
      "% of wins: 1.40\n",
      "Number of times Agent was too scared or climbed out quickly: 349\n",
      "% times Agent was too scared or climbed out quickly: 34.90\n",
      "Average score: -323.897\n",
      "\n",
      "Note: for the Naive Agent, instead of being scared with reason, it is just simply climbing out\n",
      "        for the Move Planning Agent, it cannot climb out without having the gold\n",
      "        for the Probability Agent, it can climb out without having the gold if the next move is too dangerous for it\n"
     ]
    }
   ],
   "source": [
    "# Release the Wumpus and the Naive Agent!\n",
    "\n",
    "main(\"Naive\", 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386d8855-7bbe-46a8-98fb-643a343210b6",
   "metadata": {},
   "source": [
    "### <font color=\"Green\">Move Planning Agent</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "950bca12-d421-4837-9403-18460a0c8fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready Player 1\n",
      "--------------\n",
      "Starting the game... there are 1000 episodes to play.\n",
      "Completed 100 episodes...\n",
      "Completed 200 episodes...\n",
      "Completed 300 episodes...\n",
      "Completed 400 episodes...\n",
      "Completed 500 episodes...\n",
      "Completed 600 episodes...\n",
      "Completed 700 episodes...\n",
      "Completed 800 episodes...\n",
      "Completed 900 episodes...\n",
      "\n",
      "Stats:\n",
      "------\n",
      "Number of episodes: 1000\n",
      "Number of episode wins: 195\n",
      "% of wins: 19.50\n",
      "Number of times Agent was too scared or climbed out quickly: 0\n",
      "% times Agent was too scared or climbed out quickly: 0.00\n",
      "Average score: -653.685\n",
      "\n",
      "Note: for the Naive Agent, instead of being scared with reason, it is just simply climbing out\n",
      "        for the Move Planning Agent, it cannot climb out without having the gold\n",
      "        for the Probability Agent, it can climb out without having the gold if the next move is too dangerous for it\n"
     ]
    }
   ],
   "source": [
    "# Release the Wumpus and the Move Planning Agent!\n",
    "\n",
    "main(\"MovePlanning\", 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54ed843-1289-45e0-a1b2-ad218d30e906",
   "metadata": {},
   "source": [
    "### <font color=\"Green\">Probability Agent</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b273f0a-fd1a-4937-af06-79eec82e0c44",
   "metadata": {},
   "source": [
    "#### <font color=\"Tomato\">Danger Index = 50%</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1695813c-8324-4117-92bc-c11c082dffaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready Player 1\n",
      "--------------\n",
      "Starting the game... there are 1000 episodes to play.\n",
      "Completed 100 episodes...\n",
      "Completed 200 episodes...\n",
      "Completed 300 episodes...\n",
      "Completed 400 episodes...\n",
      "Completed 500 episodes...\n",
      "Completed 600 episodes...\n",
      "Completed 700 episodes...\n",
      "Completed 800 episodes...\n",
      "Completed 900 episodes...\n",
      "\n",
      "Stats:\n",
      "------\n",
      "Number of episodes: 1000\n",
      "Number of episode wins: 192\n",
      "% of wins: 19.20\n",
      "Number of times Agent was too scared or climbed out quickly: 283\n",
      "% times Agent was too scared or climbed out quickly: 28.30\n",
      "Average score: -168.429\n",
      "\n",
      "Note: for the Naive Agent, instead of being scared with reason, it is just simply climbing out\n",
      "        for the Move Planning Agent, it cannot climb out without having the gold\n",
      "        for the Probability Agent, it can climb out without having the gold if the next move is too dangerous for it\n"
     ]
    }
   ],
   "source": [
    "# Release the Wumpus and the Probability Agent!\n",
    "\n",
    "main(\"Prob\", 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36589a-eebb-4c4b-b0b4-0548cce4c3a4",
   "metadata": {},
   "source": [
    "#### <font color=\"Tomato\">Danger Index = 5%</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccd0f028-a61d-4a2c-985e-aabc4b0fcf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready Player 1\n",
      "--------------\n",
      "Starting the game... there are 1000 episodes to play.\n",
      "Completed 100 episodes...\n",
      "Completed 200 episodes...\n",
      "Completed 300 episodes...\n",
      "Completed 400 episodes...\n",
      "Completed 500 episodes...\n",
      "Completed 600 episodes...\n",
      "Completed 700 episodes...\n",
      "Completed 800 episodes...\n",
      "Completed 900 episodes...\n",
      "\n",
      "Stats:\n",
      "------\n",
      "Number of episodes: 1000\n",
      "Number of episode wins: 204\n",
      "% of wins: 20.40\n",
      "Number of times Agent was too scared or climbed out quickly: 0\n",
      "% times Agent was too scared or climbed out quickly: 0.00\n",
      "Average score: -510.831\n",
      "\n",
      "Note: for the Naive Agent, instead of being scared with reason, it is just simply climbing out\n",
      "        for the Move Planning Agent, it cannot climb out without having the gold\n",
      "        for the Probability Agent, it can climb out without having the gold if the next move is too dangerous for it\n"
     ]
    }
   ],
   "source": [
    "# Agent Fear Index\n",
    "\n",
    "Global._agent_fear_index = .05\n",
    "\n",
    "# Release the Wumpus and the Probability Agent!\n",
    "\n",
    "main(\"Prob\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d92f3-c09c-464c-8585-eb793649a953",
   "metadata": {},
   "source": [
    "#### <font color=\"Tomato\">Individual Probability Agent Runs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9524e84-70d0-49fc-ba35-3c9cd0e7806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the Agent Fear Index to 50%\n",
    "# Update the Display variable to show the Agent in action.\n",
    "\n",
    "# Agent Fear Index\n",
    "\n",
    "Global._agent_fear_index = .5\n",
    "\n",
    "Global._display = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93144fda-3905-48f4-87ec-e928dbbfa6eb",
   "metadata": {},
   "source": [
    "##### <font color=\"Grey\">Probability Agent Run #1</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ea07f37-bc0b-4a91-b8b1-b619579299a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready Player 1\n",
      "--------------\n",
      "Starting the game... there are 1 episodes to play.\n",
      "The Episode:\n",
      "------------\n",
      "The Agent is at: \t (1, 1)\n",
      "The Wumpus is at: \t (2, 1)\n",
      "The Gold is at: \t (3, 4)\n",
      "The Pit(s) are at: \t [(2, 3)]\n",
      "The Agent is facing: \t east\n",
      "------------\n",
      "The agent score is:\t 0\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4                   G           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3            P                  \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1     A >    W                  \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 1 ----->>\n",
      "Percepts:\t['Stench']\n",
      "Status:\t\t\t*** Agent is currently exploring looking for Gold...\n",
      "Action Result:\t\tAgent is currently at (1, 1) facing east\n",
      "Action Result:\t\tDoes the Agent have the arrow? True\n",
      "Action Result:\t\tThe Agent has shot the arrow\n",
      "Action Result:\t\tArrow is travelling through room (2, 1) .. *** The Wumpus has been killed ***\n",
      "Percepts:\t['Scream']\n",
      "Status:\t\t\t*** Agent has detected the Scream from a dead Wumpus.  Setting Wumpus probability to 0..\n",
      "The agent score is:\t -11\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4                   G           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3            P                  \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1     A >    w                  \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 2 ----->>\n",
      "Percepts:\t['Stench']\n",
      "Status:\t\t\t*** Agent is currently exploring looking for Gold...\n",
      "Status:\t\t\t*** Agent is looking to move...\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid a pit...\n",
      "Status:\t\t\t*** Cases grid with 2 neighbours: [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - room and breeze list [-1, -1, 0]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[0.8000, 0.2000]]), tensor([[1., 0.]]), tensor([[1., 0.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - neighbour probabilities {'2-1': {'False': 0.800000011920929, 'True': 0.20000000298023224}, '1-2': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid the Wumpus...\n",
      "Status:\t\t\t*** Cases grid with 2 neighbours: [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - room and stench list [0, 0, 1]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[1., 0.]]), tensor([[nan, nan]]), tensor([[nan, nan]])]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - neighbour probabilities {'2-1': {'False': 1.0, 'True': 0.0}, '1-2': {'False': nan, 'True': nan}}\n",
      "Status:\t\t\t*** Evaluating room 2-1 the % that it is NOT a pit is 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 2-1 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 2-1 the % that it is NOT both is (1-p)(1-w) 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT a pit is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT a wumpus is nan\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT both is (1-p)(1-w) nan\n",
      "Status:\t\t\t*** Converting room: 1-2 : the % that it is NOT both is (1-p)(1-w) 1\n",
      "Status:\t\t\t*** The best room for the Agent to move to is 1-2\n",
      "Status:\t\t\t*** The Agent's move plan is ['TurnLeft', 'Forward']\n",
      "Action Result:\t\tAgent is currently at (1, 1) facing east\n",
      "Action Result:\t\tAgent has turned left and is now facing north\n",
      "Percepts:\t[]\n",
      "The agent score is:\t -12\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4                   G           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3            P                  \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t       ^                         \n",
      "\t 1     A      w                  \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 3 ----->>\n",
      "Percepts:\t['Stench']\n",
      "Status:\t\t\t*** Agent is currently in a movement plan...\n",
      "Move plan:\t\t\t ['Forward']\n",
      "Action from Move plan:\t\t Forward\n",
      "Move plan after action:\t\t []\n",
      "Action Result:\t\tAgent is currently at (1, 1) facing north\n",
      "Action Result:\t\tAgent is looking to move north to (1, 2)\n",
      "Action Result:\t\tValid forward move.  Agent is now at (1, 2)\n",
      "Action Result:\t\tLooking to add (1, 2) facing north (and other directions) to the visited room graph.\n",
      "Percepts:\t['Move', 'Direction']\n",
      "Action Result:\t\tLooking to add (1, 2) facing north (and other directions) to the visited room graph.\n",
      "Status:\t\t\t*** Agent has calculated the new Wumpus probability for each unknown room as 0\n",
      "The agent score is:\t -13\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4                   G           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3            P                  \n",
      "\t                                 \n",
      "\n",
      "\t       ^                         \n",
      "\t 2     A                         \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1            w                  \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 4 ----->>\n",
      "Percepts:\t[]\n",
      "Status:\t\t\t*** Agent is currently exploring looking for Gold...\n",
      "Status:\t\t\t*** Agent is looking to move...\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid a pit...\n",
      "Status:\t\t\t*** Cases grid with 3 neighbours: [[[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]], [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - room and breeze list [-1, -1, 0, 0]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[0.8000, 0.2000]]), tensor([[0.8000, 0.2000]]), tensor([[1., 0.]]), tensor([[1., 0.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - neighbour probabilities {'2-2': {'False': 0.800000011920929, 'True': 0.20000000298023224}, '1-3': {'False': 0.800000011920929, 'True': 0.20000000298023224}, '1-1': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid the Wumpus...\n",
      "Status:\t\t\t*** Cases grid with 3 neighbours: [[[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]], [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - room and stench list [0, 0, 0, 0]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[1., 0.]]), tensor([[1., 0.]]), tensor([[1., 0.]]), tensor([[1., 0.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - neighbour probabilities {'2-2': {'False': 1.0, 'True': 0.0}, '1-3': {'False': 1.0, 'True': 0.0}, '1-1': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Evaluating room 2-2 the % that it is NOT a pit is 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 2-2 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 2-2 the % that it is NOT both is (1-p)(1-w) 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 1-3 the % that it is NOT a pit is 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 1-3 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-3 the % that it is NOT both is (1-p)(1-w) 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 1-1 the % that it is NOT a pit is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-1 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-1 the % that it is NOT both is (1-p)(1-w) 1.0\n",
      "Status:\t\t\t*** Path Len from  1-2 to 2-2 while facing north is 2\n",
      "Status:\t\t\t*** Path Len from  1-2 to 1-3 while facing north is 1\n",
      "Status:\t\t\t*** The best room for the Agent to move to is 1-3\n",
      "Status:\t\t\t*** The Agent's move plan is ['Forward']\n",
      "Action Result:\t\tAgent is currently at (1, 2) facing north\n",
      "Action Result:\t\tAgent is looking to move north to (1, 3)\n",
      "Action Result:\t\tValid forward move.  Agent is now at (1, 3)\n",
      "Action Result:\t\tLooking to add (1, 3) facing north (and other directions) to the visited room graph.\n",
      "Percepts:\t['Move', 'Direction']\n",
      "Action Result:\t\tLooking to add (1, 3) facing north (and other directions) to the visited room graph.\n",
      "Status:\t\t\t*** Agent has calculated the new Wumpus probability for each unknown room as 0\n",
      "The agent score is:\t -14\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4                   G           \n",
      "\t                                 \n",
      "\n",
      "\t       ^                         \n",
      "\t 3     A      P                  \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1            w                  \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 5 ----->>\n",
      "Percepts:\t['Breeze']\n",
      "Status:\t\t\t*** Agent is currently exploring looking for Gold...\n",
      "Status:\t\t\t*** Agent is looking to move...\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid a pit...\n",
      "Status:\t\t\t*** Cases grid with 3 neighbours: [[[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]], [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - room and breeze list [-1, -1, 0, 1]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[0.6667, 0.3333]]), tensor([[0., 1.]]), tensor([[1., 0.]]), tensor([[0., 1.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - neighbour probabilities {'2-3': {'False': 0.6666666865348816, 'True': 0.3333333432674408}, '1-4': {'False': 0.0, 'True': 1.0}, '1-2': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid the Wumpus...\n",
      "Status:\t\t\t*** Cases grid with 3 neighbours: [[[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]], [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - room and stench list [0, 0, 0, 0]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[1., 0.]]), tensor([[1., 0.]]), tensor([[1., 0.]]), tensor([[1., 0.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - neighbour probabilities {'2-3': {'False': 1.0, 'True': 0.0}, '1-4': {'False': 1.0, 'True': 0.0}, '1-2': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Evaluating room 2-3 the % that it is NOT a pit is 0.6666666865348816\n",
      "Status:\t\t\t*** Evaluating room 2-3 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 2-3 the % that it is NOT both is (1-p)(1-w) 0.6666666865348816\n",
      "Status:\t\t\t*** Evaluating room 1-4 the % that it is NOT a pit is 0.0\n",
      "Status:\t\t\t*** Evaluating room 1-4 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-4 the % that it is NOT both is (1-p)(1-w) 0.0\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT a pit is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT both is (1-p)(1-w) 1.0\n",
      "Status:\t\t\t*** The best room for the Agent to move to is 2-3\n",
      "Status:\t\t\t*** The Agent's move plan is ['TurnRight', 'Forward']\n",
      "Action Result:\t\tAgent is currently at (1, 3) facing north\n",
      "Action Result:\t\tAgent has turned right and is now facing east\n",
      "Percepts:\t[]\n",
      "The agent score is:\t -15\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4                   G           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     A >    P                  \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1            w                  \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 6 ----->>\n",
      "Percepts:\t['Breeze']\n",
      "Status:\t\t\t*** Agent is currently in a movement plan...\n",
      "Move plan:\t\t\t ['Forward']\n",
      "Action from Move plan:\t\t Forward\n",
      "Move plan after action:\t\t []\n",
      "Action Result:\t\tAgent is currently at (1, 3) facing east\n",
      "Action Result:\t\tAgent is looking to move east to (2, 3)\n",
      "Action Result:\t\tValid forward move.  Agent is now at (2, 3)\n",
      "Action Result:\t\t*** Agent has fallen into a pit ***\n",
      "The agent score is:\t -1016\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4                   G           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3            A >                \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1            w                  \n",
      "\t                                 \n",
      "\n",
      "Episode Complete: the Agent's final score is: -1016 in 6 moves.\n",
      "episode_total_score: -1016\n",
      "\n",
      "Stats:\n",
      "------\n",
      "Number of episodes: 1\n",
      "Number of episode wins: 0\n",
      "% of wins: 0.00\n",
      "Number of times Agent was too scared or climbed out quickly: 0\n",
      "% times Agent was too scared or climbed out quickly: 0.00\n",
      "Average score: -1016.0\n",
      "\n",
      "Note: for the Naive Agent, instead of being scared with reason, it is just simply climbing out\n",
      "        for the Move Planning Agent, it cannot climb out without having the gold\n",
      "        for the Probability Agent, it can climb out without having the gold if the next move is too dangerous for it\n"
     ]
    }
   ],
   "source": [
    "# Release the Wumpus and the Probability Agent!\n",
    "\n",
    "main(\"Prob\", 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4007ced-c335-4f84-89c0-e675bba7dcfb",
   "metadata": {},
   "source": [
    "##### <font color=\"Grey\">Probability Agent Run #2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4e7a33f-2cc9-49b1-a9b9-3e8bec9180b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready Player 1\n",
      "--------------\n",
      "Starting the game... there are 1 episodes to play.\n",
      "The Episode:\n",
      "------------\n",
      "The Agent is at: \t (1, 1)\n",
      "The Wumpus is at: \t (1, 3)\n",
      "The Gold is at: \t (2, 3)\n",
      "The Pit(s) are at: \t [(1, 4), (3, 3), (3, 4), (4, 4)]\n",
      "The Agent is facing: \t east\n",
      "------------\n",
      "The agent score is:\t 0\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     W      G      P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1     A >                       \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 1 ----->>\n",
      "Percepts:\t[]\n",
      "Status:\t\t\t*** Agent is currently exploring looking for Gold...\n",
      "Status:\t\t\t*** Agent is looking to move...\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid a pit...\n",
      "Status:\t\t\t*** Cases grid with 2 neighbours: [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - room and breeze list [-1, -1, 0]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[0.8000, 0.2000]]), tensor([[1., 0.]]), tensor([[1., 0.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - neighbour probabilities {'2-1': {'False': 0.800000011920929, 'True': 0.20000000298023224}, '1-2': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid the Wumpus...\n",
      "Status:\t\t\t*** Cases grid with 2 neighbours: [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - room and stench list [-1, -1, 0]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[0.9333, 0.0667]]), tensor([[1., 0.]]), tensor([[1., 0.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - neighbour probabilities {'2-1': {'False': 0.9333333373069763, 'True': 0.06666667014360428}, '1-2': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Evaluating room 2-1 the % that it is NOT a pit is 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 2-1 the % that it is NOT a wumpus is 0.9333333373069763\n",
      "Status:\t\t\t*** Evaluating room 2-1 the % that it is NOT both is (1-p)(1-w) 0.7466666809717815\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT a pit is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT both is (1-p)(1-w) 1.0\n",
      "Status:\t\t\t*** The best room for the Agent to move to is 1-2\n",
      "Status:\t\t\t*** The Agent's move plan is ['TurnLeft', 'Forward']\n",
      "Action Result:\t\tAgent is currently at (1, 1) facing east\n",
      "Action Result:\t\tAgent has turned left and is now facing north\n",
      "Percepts:\t[]\n",
      "The agent score is:\t -1\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     W      G      P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t       ^                         \n",
      "\t 1     A                         \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 2 ----->>\n",
      "Percepts:\t[]\n",
      "Status:\t\t\t*** Agent is currently in a movement plan...\n",
      "Move plan:\t\t\t ['Forward']\n",
      "Action from Move plan:\t\t Forward\n",
      "Move plan after action:\t\t []\n",
      "Action Result:\t\tAgent is currently at (1, 1) facing north\n",
      "Action Result:\t\tAgent is looking to move north to (1, 2)\n",
      "Action Result:\t\tValid forward move.  Agent is now at (1, 2)\n",
      "Action Result:\t\tLooking to add (1, 2) facing north (and other directions) to the visited room graph.\n",
      "Percepts:\t['Move', 'Direction']\n",
      "Action Result:\t\tLooking to add (1, 2) facing north (and other directions) to the visited room graph.\n",
      "Status:\t\t\t*** Agent has calculated the new Wumpus probability for each unknown room as 0.07692307692307693\n",
      "The agent score is:\t -2\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     W      G      P           \n",
      "\t                                 \n",
      "\n",
      "\t       ^                         \n",
      "\t 2     A                         \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 3 ----->>\n",
      "Percepts:\t['Stench']\n",
      "Status:\t\t\t*** Agent is currently exploring looking for Gold...\n",
      "Action Result:\t\tAgent is currently at (1, 2) facing north\n",
      "Action Result:\t\tDoes the Agent have the arrow? True\n",
      "Action Result:\t\tThe Agent has shot the arrow\n",
      "Action Result:\t\tArrow is travelling through room (1, 3) .. *** The Wumpus has been killed ***\n",
      "Percepts:\t['Scream']\n",
      "Status:\t\t\t*** Agent has detected the Scream from a dead Wumpus.  Setting Wumpus probability to 0..\n",
      "The agent score is:\t -13\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     w      G      P           \n",
      "\t                                 \n",
      "\n",
      "\t       ^                         \n",
      "\t 2     A                         \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 4 ----->>\n",
      "Percepts:\t['Stench']\n",
      "Status:\t\t\t*** Agent is currently exploring looking for Gold...\n",
      "Status:\t\t\t*** Agent is looking to move...\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid a pit...\n",
      "Status:\t\t\t*** Cases grid with 3 neighbours: [[[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]], [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - room and breeze list [-1, -1, 0, 0]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[0.8000, 0.2000]]), tensor([[0.8000, 0.2000]]), tensor([[1., 0.]]), tensor([[1., 0.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - neighbour probabilities {'2-2': {'False': 0.800000011920929, 'True': 0.20000000298023224}, '1-3': {'False': 0.800000011920929, 'True': 0.20000000298023224}, '1-1': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid the Wumpus...\n",
      "Status:\t\t\t*** Cases grid with 3 neighbours: [[[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]], [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - room and stench list [0, 0, 0, 1]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[1., 0.]]), tensor([[1., 0.]]), tensor([[nan, nan]]), tensor([[nan, nan]])]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - neighbour probabilities {'2-2': {'False': 1.0, 'True': 0.0}, '1-3': {'False': 1.0, 'True': 0.0}, '1-1': {'False': nan, 'True': nan}}\n",
      "Status:\t\t\t*** Evaluating room 2-2 the % that it is NOT a pit is 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 2-2 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 2-2 the % that it is NOT both is (1-p)(1-w) 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 1-3 the % that it is NOT a pit is 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 1-3 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-3 the % that it is NOT both is (1-p)(1-w) 0.800000011920929\n",
      "Status:\t\t\t*** Evaluating room 1-1 the % that it is NOT a pit is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-1 the % that it is NOT a wumpus is nan\n",
      "Status:\t\t\t*** Evaluating room 1-1 the % that it is NOT both is (1-p)(1-w) nan\n",
      "Status:\t\t\t*** Converting room: 1-1 : the % that it is NOT both is (1-p)(1-w) 1\n",
      "Status:\t\t\t*** Path Len from  1-2 to 2-2 while facing north is 2\n",
      "Status:\t\t\t*** Path Len from  1-2 to 1-3 while facing north is 1\n",
      "Status:\t\t\t*** The best room for the Agent to move to is 1-3\n",
      "Status:\t\t\t*** The Agent's move plan is ['Forward']\n",
      "Action Result:\t\tAgent is currently at (1, 2) facing north\n",
      "Action Result:\t\tAgent is looking to move north to (1, 3)\n",
      "Action Result:\t\tValid forward move.  Agent is now at (1, 3)\n",
      "Action Result:\t\tLooking to add (1, 3) facing north (and other directions) to the visited room graph.\n",
      "Percepts:\t['Move', 'Direction']\n",
      "Action Result:\t\tLooking to add (1, 3) facing north (and other directions) to the visited room graph.\n",
      "Status:\t\t\t*** Agent has calculated the new Wumpus probability for each unknown room as 0\n",
      "The agent score is:\t -14\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t       ^                         \n",
      "\t 3     A      G      P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 5 ----->>\n",
      "Percepts:\t['Breeze']\n",
      "Status:\t\t\t*** Agent is currently exploring looking for Gold...\n",
      "Status:\t\t\t*** Agent is looking to move...\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid a pit...\n",
      "Status:\t\t\t*** Cases grid with 3 neighbours: [[[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]], [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - room and breeze list [-1, -1, 0, 1]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[0.6667, 0.3333]]), tensor([[0., 1.]]), tensor([[1., 0.]]), tensor([[0., 1.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - neighbour probabilities {'2-3': {'False': 0.6666666865348816, 'True': 0.3333333432674408}, '1-4': {'False': 0.0, 'True': 1.0}, '1-2': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid the Wumpus...\n",
      "Status:\t\t\t*** Cases grid with 3 neighbours: [[[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]], [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - room and stench list [0, 0, 0, 0]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[1., 0.]]), tensor([[1., 0.]]), tensor([[1., 0.]]), tensor([[1., 0.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - neighbour probabilities {'2-3': {'False': 1.0, 'True': 0.0}, '1-4': {'False': 1.0, 'True': 0.0}, '1-2': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Evaluating room 2-3 the % that it is NOT a pit is 0.6666666865348816\n",
      "Status:\t\t\t*** Evaluating room 2-3 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 2-3 the % that it is NOT both is (1-p)(1-w) 0.6666666865348816\n",
      "Status:\t\t\t*** Evaluating room 1-4 the % that it is NOT a pit is 0.0\n",
      "Status:\t\t\t*** Evaluating room 1-4 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-4 the % that it is NOT both is (1-p)(1-w) 0.0\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT a pit is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT both is (1-p)(1-w) 1.0\n",
      "Status:\t\t\t*** The best room for the Agent to move to is 2-3\n",
      "Status:\t\t\t*** The Agent's move plan is ['TurnRight', 'Forward']\n",
      "Action Result:\t\tAgent is currently at (1, 3) facing north\n",
      "Action Result:\t\tAgent has turned right and is now facing east\n",
      "Percepts:\t[]\n",
      "The agent score is:\t -15\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     A >    G      P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 6 ----->>\n",
      "Percepts:\t['Breeze']\n",
      "Status:\t\t\t*** Agent is currently in a movement plan...\n",
      "Move plan:\t\t\t ['Forward']\n",
      "Action from Move plan:\t\t Forward\n",
      "Move plan after action:\t\t []\n",
      "Action Result:\t\tAgent is currently at (1, 3) facing east\n",
      "Action Result:\t\tAgent is looking to move east to (2, 3)\n",
      "Action Result:\t\tValid forward move.  Agent is now at (2, 3)\n",
      "Action Result:\t\tLooking to add (2, 3) facing east (and other directions) to the visited room graph.\n",
      "Percepts:\t['Move', 'Direction']\n",
      "Action Result:\t\tLooking to add (2, 3) facing east (and other directions) to the visited room graph.\n",
      "Status:\t\t\t*** Agent has calculated the new Wumpus probability for each unknown room as 0\n",
      "The agent score is:\t -16\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     w      A >    P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 7 ----->>\n",
      "Percepts:\t['Stench', 'Breeze', 'Glitter']\n",
      "Status:\t\t\t*** Agent is currently exploring looking for Gold...\n",
      "Status:\t\t\t*** Agent has detected the Gold and will now grab it...\n",
      "Status:\t\t\tAgent is creating an exit plan from (2, 3)-east to (1, 1)\n",
      "Status:\t\t\tAgent Shortest A* path: ['(2, 3)-east', '(2, 3)-north', '(2, 3)-west', '(1, 3)-west', '(1, 3)-south', '(1, 2)-south', '(1, 1)-south', '(1, 1)-east']\n",
      "Status:\t\t\tIndex of (1,1) is:  (1, 1)-south at node 6 in the path.\n",
      "Status:\t\t\tAgent new short path = ['(2, 3)-east', '(2, 3)-north', '(2, 3)-west', '(1, 3)-west', '(1, 3)-south', '(1, 2)-south', '(1, 1)-south']\n",
      "Status:\t\t\t*** The Agent's exit plan is: ['TurnLeft', 'TurnLeft', 'Forward', 'TurnLeft', 'Forward', 'Forward', 'Climb']\n",
      "Action Result:\t\tAgent is currently at (2, 3) facing east\n",
      "Action Result:\t\t*** The Agent has grabbed the gold ***\n",
      "Percepts:\t[]\n",
      "The agent score is:\t -17\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     w      A >    P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 8 ----->>\n",
      "Percepts:\t['Stench', 'Breeze', 'Glitter']\n",
      "Status:\t\t\t*** Agent is currently executing its exit plan...\n",
      "Exit plan:\t\t\t ['TurnLeft', 'TurnLeft', 'Forward', 'TurnLeft', 'Forward', 'Forward', 'Climb']\n",
      "Action from Exit plan:\t\t TurnLeft\n",
      "Exit plan after action:\t\t ['TurnLeft', 'Forward', 'TurnLeft', 'Forward', 'Forward', 'Climb']\n",
      "Action Result:\t\tAgent is currently at (2, 3) facing east\n",
      "Action Result:\t\tAgent has turned left and is now facing north\n",
      "Percepts:\t[]\n",
      "The agent score is:\t -18\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t              ^                  \n",
      "\t 3     w      A      P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 9 ----->>\n",
      "Percepts:\t['Stench', 'Breeze', 'Glitter']\n",
      "Status:\t\t\t*** Agent is currently executing its exit plan...\n",
      "Exit plan:\t\t\t ['TurnLeft', 'Forward', 'TurnLeft', 'Forward', 'Forward', 'Climb']\n",
      "Action from Exit plan:\t\t TurnLeft\n",
      "Exit plan after action:\t\t ['Forward', 'TurnLeft', 'Forward', 'Forward', 'Climb']\n",
      "Action Result:\t\tAgent is currently at (2, 3) facing north\n",
      "Action Result:\t\tAgent has turned left and is now facing west\n",
      "Percepts:\t[]\n",
      "The agent score is:\t -19\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     w    < A      P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 10 ----->>\n",
      "Percepts:\t['Stench', 'Breeze', 'Glitter']\n",
      "Status:\t\t\t*** Agent is currently executing its exit plan...\n",
      "Exit plan:\t\t\t ['Forward', 'TurnLeft', 'Forward', 'Forward', 'Climb']\n",
      "Action from Exit plan:\t\t Forward\n",
      "Exit plan after action:\t\t ['TurnLeft', 'Forward', 'Forward', 'Climb']\n",
      "Action Result:\t\tAgent is currently at (2, 3) facing west\n",
      "Action Result:\t\tAgent is looking to move west to (1, 3)\n",
      "Action Result:\t\tValid forward move.  Agent is now at (1, 3)\n",
      "Action Result:\t\tLooking to add (1, 3) facing west (and other directions) to the visited room graph.\n",
      "Percepts:\t['Move', 'Direction']\n",
      "Action Result:\t\tLooking to add (1, 3) facing west (and other directions) to the visited room graph.\n",
      "Status:\t\t\t*** Agent has calculated the new Wumpus probability for each unknown room as 0\n",
      "The agent score is:\t -20\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3   < A             P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 11 ----->>\n",
      "Percepts:\t['Breeze']\n",
      "Status:\t\t\t*** Agent is currently executing its exit plan...\n",
      "Exit plan:\t\t\t ['TurnLeft', 'Forward', 'Forward', 'Climb']\n",
      "Action from Exit plan:\t\t TurnLeft\n",
      "Exit plan after action:\t\t ['Forward', 'Forward', 'Climb']\n",
      "Action Result:\t\tAgent is currently at (1, 3) facing west\n",
      "Action Result:\t\tAgent has turned left and is now facing south\n",
      "Percepts:\t[]\n",
      "The agent score is:\t -21\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     A             P           \n",
      "\t       V                         \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 12 ----->>\n",
      "Percepts:\t['Breeze']\n",
      "Status:\t\t\t*** Agent is currently executing its exit plan...\n",
      "Exit plan:\t\t\t ['Forward', 'Forward', 'Climb']\n",
      "Action from Exit plan:\t\t Forward\n",
      "Exit plan after action:\t\t ['Forward', 'Climb']\n",
      "Action Result:\t\tAgent is currently at (1, 3) facing south\n",
      "Action Result:\t\tAgent is looking to move south to (1, 2)\n",
      "Action Result:\t\tValid forward move.  Agent is now at (1, 2)\n",
      "Action Result:\t\tLooking to add (1, 2) facing south (and other directions) to the visited room graph.\n",
      "Percepts:\t['Move', 'Direction']\n",
      "Action Result:\t\tLooking to add (1, 2) facing south (and other directions) to the visited room graph.\n",
      "Status:\t\t\t*** Agent has calculated the new Wumpus probability for each unknown room as 0\n",
      "The agent score is:\t -22\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     w             P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2     A                         \n",
      "\t       V                         \n",
      "\n",
      "\t                                 \n",
      "\t 1                               \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 13 ----->>\n",
      "Percepts:\t['Stench']\n",
      "Status:\t\t\t*** Agent is currently executing its exit plan...\n",
      "Exit plan:\t\t\t ['Forward', 'Climb']\n",
      "Action from Exit plan:\t\t Forward\n",
      "Exit plan after action:\t\t ['Climb']\n",
      "Action Result:\t\tAgent is currently at (1, 2) facing south\n",
      "Action Result:\t\tAgent is looking to move south to (1, 1)\n",
      "Action Result:\t\tValid forward move.  Agent is now at (1, 1)\n",
      "Action Result:\t\tLooking to add (1, 1) facing south (and other directions) to the visited room graph.\n",
      "Percepts:\t['Move', 'Direction']\n",
      "Action Result:\t\tLooking to add (1, 1) facing south (and other directions) to the visited room graph.\n",
      "Status:\t\t\t*** Agent has calculated the new Wumpus probability for each unknown room as 0\n",
      "The agent score is:\t -23\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     w             P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1     A                         \n",
      "\t       V                         \n",
      "\n",
      ">>----- Agent Move 14 ----->>\n",
      "Percepts:\t[]\n",
      "Status:\t\t\t*** Agent is currently executing its exit plan...\n",
      "Exit plan:\t\t\t ['Climb']\n",
      "Action from Exit plan:\t\t Climb\n",
      "Exit plan after action:\t\t []\n",
      "Action Result:\t\tAgent is currently at (1, 1) facing south\n",
      "Action Result:\t\t*** The Agent is climbing out with the gold :-) ***\n",
      "The agent score is:\t 976\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4     P             P      P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3     w             P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2                               \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1     A                         \n",
      "\t       V                         \n",
      "\n",
      "Episode Complete: the Agent's final score is: 976 in 14 moves.\n",
      "episode_total_score: 976\n",
      "\n",
      "Stats:\n",
      "------\n",
      "Number of episodes: 1\n",
      "Number of episode wins: 1\n",
      "% of wins: 100.00\n",
      "Number of times Agent was too scared or climbed out quickly: 0\n",
      "% times Agent was too scared or climbed out quickly: 0.00\n",
      "Average score: 976.0\n",
      "\n",
      "Note: for the Naive Agent, instead of being scared with reason, it is just simply climbing out\n",
      "        for the Move Planning Agent, it cannot climb out without having the gold\n",
      "        for the Probability Agent, it can climb out without having the gold if the next move is too dangerous for it\n"
     ]
    }
   ],
   "source": [
    "# Release the Wumpus and the Probability Agent!\n",
    "\n",
    "main(\"Prob\", 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060670d-de64-402d-ba36-1b075d55af38",
   "metadata": {},
   "source": [
    "##### <font color=\"Grey\">Probability Agent Run #3</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60b798b7-a819-4564-a5f3-5683fd21f269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready Player 1\n",
      "--------------\n",
      "Starting the game... there are 1 episodes to play.\n",
      "The Episode:\n",
      "------------\n",
      "The Agent is at: \t (1, 1)\n",
      "The Wumpus is at: \t (2, 2)\n",
      "The Gold is at: \t (3, 1)\n",
      "The Pit(s) are at: \t [(2, 1), (3, 3), (4, 4)]\n",
      "The Agent is facing: \t east\n",
      "------------\n",
      "The agent score is:\t 0\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4                          P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3                   P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2            W                  \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1     A >    P      G           \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 1 ----->>\n",
      "Percepts:\t['Breeze']\n",
      "Status:\t\t\t*** Agent is currently exploring looking for Gold...\n",
      "Status:\t\t\t*** Agent is looking to move...\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid a pit...\n",
      "Status:\t\t\t*** Cases grid with 2 neighbours: [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - room and breeze list [-1, -1, 1]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[0.3333, 0.6667]]), tensor([[0.3333, 0.6667]]), tensor([[0., 1.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the pit - neighbour probabilities {'2-1': {'False': 0.3333333432674408, 'True': 0.6666666865348816}, '1-2': {'False': 0.3333333432674408, 'True': 0.6666666865348816}}\n",
      "Status:\t\t\t*** Agent is looking to see which move can avoid the Wumpus...\n",
      "Status:\t\t\t*** Cases grid with 2 neighbours: [[[1.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 1.0]]]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - room and stench list [-1, -1, 0]\n",
      "Status:\t\t\t*** Running the BayesianNetwork model - Tensors: [tensor([[0.9333, 0.0667]]), tensor([[1., 0.]]), tensor([[1., 0.]])]\n",
      "Status:\t\t\t*** Evaluating probability for the Wumpus - neighbour probabilities {'2-1': {'False': 0.9333333373069763, 'True': 0.06666667014360428}, '1-2': {'False': 1.0, 'True': 0.0}}\n",
      "Status:\t\t\t*** Evaluating room 2-1 the % that it is NOT a pit is 0.3333333432674408\n",
      "Status:\t\t\t*** Evaluating room 2-1 the % that it is NOT a wumpus is 0.9333333373069763\n",
      "Status:\t\t\t*** Evaluating room 2-1 the % that it is NOT both is (1-p)(1-w) 0.31111112170749244\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT a pit is 0.3333333432674408\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT a wumpus is 1.0\n",
      "Status:\t\t\t*** Evaluating room 1-2 the % that it is NOT both is (1-p)(1-w) 0.3333333432674408\n",
      "Status:\t\t\t*** The best room for the Agent to move to is Exit\n",
      "Status:\t\t\t*** Next moves have been deemed too dangerous.  Agent is bailing.\n",
      "Status:\t\t\tAgent is creating an exit plan from (1, 1)-east to (1, 1)\n",
      "Status:\t\t\tAgent Shortest A* path: ['(1, 1)-east']\n",
      "Status:\t\t\tIndex of (1,1) is:  (1, 1)-east at node 0 in the path.\n",
      "Status:\t\t\tAgent new short path = ['(1, 1)-east']\n",
      "Status:\t\t\t*** The Agent's exit plan is: ['Climb']\n",
      "Action Result:\t\tAgent is currently at (1, 1) facing east\n",
      "Action Result:\t\tThere is no gold in room (1, 1)\n",
      "Percepts:\t[]\n",
      "The agent score is:\t -1\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4                          P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3                   P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2            W                  \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1     A >    P      G           \n",
      "\t                                 \n",
      "\n",
      ">>----- Agent Move 2 ----->>\n",
      "Percepts:\t['Breeze']\n",
      "Status:\t\t\t*** Agent is currently executing its exit plan...\n",
      "Exit plan:\t\t\t ['Climb']\n",
      "Action from Exit plan:\t\t Climb\n",
      "Exit plan after action:\t\t []\n",
      "Action Result:\t\tAgent is currently at (1, 1) facing east\n",
      "Action Result:\t\t*** The Agent is climbing out without the gold :-( ***\n",
      "The agent score is:\t -2\n",
      "\n",
      "\t       1      2      3      4    \n",
      "\n",
      "\t                                 \n",
      "\t 4                          P    \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 3                   P           \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 2            W                  \n",
      "\t                                 \n",
      "\n",
      "\t                                 \n",
      "\t 1     A >    P      G           \n",
      "\t                                 \n",
      "\n",
      "Episode Complete: the Agent's final score is: -2 in 2 moves.\n",
      "episode_total_score: -2\n",
      "\n",
      "Stats:\n",
      "------\n",
      "Number of episodes: 1\n",
      "Number of episode wins: 0\n",
      "% of wins: 0.00\n",
      "Number of times Agent was too scared or climbed out quickly: 1\n",
      "% times Agent was too scared or climbed out quickly: 100.00\n",
      "Average score: -2.0\n",
      "\n",
      "Note: for the Naive Agent, instead of being scared with reason, it is just simply climbing out\n",
      "        for the Move Planning Agent, it cannot climb out without having the gold\n",
      "        for the Probability Agent, it can climb out without having the gold if the next move is too dangerous for it\n"
     ]
    }
   ],
   "source": [
    "# Release the Wumpus and the Probability Agent!\n",
    "\n",
    "main(\"Prob\", 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14e665-5bff-480a-9c5f-e8dd7c6faba2",
   "metadata": {},
   "source": [
    "## <font color=\"Blue\">Agent Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68540a07-df4d-4354-bd0d-b45336a6fe21",
   "metadata": {},
   "source": [
    "For the **Naive Agent**, all movements are completely random.  The Naive Agent can simply climb out at the start of the episode.  As the movements are completely random, it only wins on average ~1% of the time.  Approximately 30-35% of the time, the Naive Agent simply climbs out or does a few other actions first.  However, the average score over 1000 episodes is ~-300 to -400.\n",
    "\n",
    "For the **Move Planning Agent** the movements and shooting the arrow are random.  It creates an exit plan once it grabs the gold and it cannot climb out without having the gold. It wins about 17-20% of the time as it cannot climb out quickly.  However, it's score over 1000 episodes is ~ -700 as it will get killed more often by a pit or the Wumpus.\n",
    "\n",
    "For the **Probability Agent**, the movements are probabilistic and the arrow is only shot (in this instantiation) when the stench of the Wumpus is detected to give it the best chance of killing the Wumpus.  At a 50% danger / fear index (i.e., if the room options for its next move is less than 50% safe to go into a room, the Agent will bail out and invoke its exit plan), it wins about 15-17% of the time, bails out about 30% of the episodes but has a pretty good average score over 1000 episodes of -200.  At a 5% danger / fear index, it wins slightly more at about 20% of the time, bails out 0% of the time but has a lower average score of -700 as it will get killed more often by a pit or the Wumpus.\n",
    "\n",
    "In summary, the more time the Agent spends in the cave, the greater the chance that it will find the gold and win.  However, it will die more so that will bring down its overall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46d92c-9a8a-4fd0-82bf-5cc79bafe3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
